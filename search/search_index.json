{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"ReadStore Command Line Interface (CLI)","text":"<p>The ReadStore Command-Line Interface (CLI) is a powerful tool for uploading and managing your genomic data. With the ReadStore CLI, you can upload FASTQ files directly to the ReadStore database, as well as access and manage Projects, Datasets, metadata, and attachment files with ease.</p> <p>The CLI can be run from your shell or terminal and is designed for seamless integration into data pipelines and scripts, enabling efficient automation of data management tasks. This flexibility allows you to integrate the ReadStore CLI within any bioinformatics application or pipeline, streamlining data uploads, access, and organization within ReadStore.</p> <p>By embedding the ReadStore CLI in your bioinformatics workflows, you can improve efficiency, reduce manual tasks, and ensure your data is readily accessible for analysis and collaboration.</p> <p>Find more information on www.evo-byte.com/readstore</p> <p>For technical questions or problems with the install please contact support@evo-byte.com</p>"},{"location":"CHANGELOG/","title":"Changelog","text":""},{"location":"CHANGELOG/#130-2025-02-11","title":"[1.3.0] - 2025-02-11","text":"<p>Features</p> <ul> <li>Add create and update methods for projects and datasets into command line</li> </ul> <p>Updates</p> <ul> <li>Improve code format</li> </ul> <p>Bugfixes</p> <ul> <li>ProData upload ensure dataset id OR name is specified</li> </ul>"},{"location":"CHANGELOG/#120-2024-12-22","title":"[1.2.0] - 2024-12-22","text":"<p>Features - Update rsbasic client to complete CRUD methods (create, read, update, delete) for Projects, Datasets, and FASTQ files     - create_project     - update_project     - delete_project     - list_fq_files     - create_fq_file     - update_fq_file     - delete_fq_file     - create_fastq_dataset     - update_fastq_dataset</p> <p>Updates</p> <ul> <li>Improve Error messages</li> </ul> <p>Bugfixes</p> <ul> <li>Fix error message when accessing read file path on non-existing datasets</li> </ul>"},{"location":"CHANGELOG/#110-2024-12-01","title":"[1.1.0] - 2024-12-01","text":"<p>Features</p> <ul> <li>Add method pro-data upload</li> <li>Add method pro-data list</li> <li>Add method pro-data get</li> <li>Add method pro-data delete</li> <li>Add readstore_template.csv for uploading file</li> </ul> <p>Updates</p> <ul> <li>upload_fastq: Add fastq_name and read_type arguments to enable definition of FASTQ names and read types</li> <li>Update backend endpoint to api_x_v1</li> </ul>"},{"location":"CHANGELOG/#102-2024-11-14","title":"[1.0.2] - 2024-11-14","text":"<p>Feat Add import fastq function</p>"},{"location":"CHANGELOG/#101-2024-10-30","title":"[1.0.1] - 2024-10-30","text":"<p>Update ReadMe and License</p>"},{"location":"CHANGELOG/#100-2024-10-30","title":"[1.0.0] - 2024-10-30","text":"<p>Initial Version</p>"},{"location":"readme/","title":"Readme","text":""},{"location":"readme/#readstore-cli","title":"ReadStore CLI","text":"<p>This README describes the ReadStore Command Line Interface (CLI). </p> <p>The full ReadStore Basic documentation is available here </p> <p>The ReadStore CLI is used to upload FASTQ files and Processed Data to the ReadStore database and access Projects, Datasets, metadata and attachment files. The ReadStore CLI enables you to automate your bioinformatics pipelines by providing simple and standardized access to datasets.</p> <p>Check the ReadStore Github repository for more information how to get started.</p> <p>More infos on the ReadStore website https://evo-byte.com/readstore/</p> <p>Tutorials and Intro Videos how to get started: https://www.youtube.com/@evobytedigitalbio</p> <p>Blog posts and How-Tos: https://evo-byte.com/blog/</p> <p>For general questions reach out to info@evo-byte.com or in case of technical problems to support@evo-byte.com</p> <p>Happy analysis :)</p>"},{"location":"readme/#table-of-contents","title":"Table of Contents","text":"<ul> <li>Description</li> <li>Security and Permissions</li> <li>Installation</li> <li>ReadStore API</li> <li>Usage<ul> <li>Quickstart</li> <li>CLI Configuration</li> <li>FASTQ Upload</li> <li>Access Projects</li> <li>Access Datasets</li> <li>Access Processed Data</li> </ul> </li> <li>Contributing</li> <li>License</li> <li>Credits and Acknowledgments</li> </ul>"},{"location":"readme/#the-lean-solution-for-managing-ngs-and-omics-data","title":"The Lean Solution for Managing NGS and Omics Data","text":"<p>ReadStore is a platform for storing, managing, and integrating genomic data. It accelerates analysis and offers an easy way to manage and share FASTQ files, NGS and omics datasets and processed datasets.  With built-in project and metadata management, ReadStore structures your workflows, and its collaborative user interface enhances teamwork \u2014 so you can focus on generating insights.</p> <p>The integrated Webservice (API) enables your to directly retrieve data from ReadStore via the terminal Command-Line-Interface (CLI) or Python / R SDKs. </p> <p>The ReadStore Basic version provides a local web server with simple user management. For organization-wide deployment, advanced user and group management, or cloud integration, please check out the ReadStore Advanced versions and contact us at info@evo-byte.com.</p>"},{"location":"readme/#description","title":"Description","text":"<p>The ReadStore Command-Line Interface (CLI) is a powerful tool for uploading and managing your omics data. With the ReadStore CLI, you can upload FASTQ files and Processed Data directly to the ReadStore database, as well as access and manage Projects, Datasets, metadata, and attachment files with ease.</p> <p>The CLI can be run from your shell or terminal and is designed for seamless integration into data pipelines and scripts, enabling efficient automation of data management tasks. This flexibility allows you to integrate the ReadStore CLI within any bioinformatics application or pipeline, streamlining data uploads, access, and organization within ReadStore.</p> <p>By embedding the ReadStore CLI in your bioinformatics workflows, you can improve efficiency, reduce manual tasks, and ensure your data is readily accessible for analysis and collaboration.</p>"},{"location":"readme/#security-and-permissions","title":"Security and Permissions","text":"<p>PLEASE READ AND FOLLOW THESE INSTRUCTIONS CAREFULLY!</p>"},{"location":"readme/#user-accounts-and-token","title":"User Accounts and Token","text":"<p>Using the CLI with a ReadStore server requires an active User Account and a Token. You should never enter your user account password when working with the CLI.</p> <p>To retrieve your token:</p> <ol> <li> <p>Login to the ReadStore web app via your browser</p> </li> <li> <p>Navigate to <code>Settings</code> page and click on <code>Token</code></p> </li> <li>If needed you can regenerate your token (<code>Reset</code>). This will invalidate the previous token</li> </ol> <p>For uploading FASTQ files or Processed Data your User Account needs to have <code>Staging Permission</code>. If you can check this in the <code>Settings</code> page of your account. If you not have <code>Staging Permission</code>, ask the ReadStore server Admin to grant you permission.</p>"},{"location":"readme/#cli-configuration","title":"CLI Configuration","text":"<p>After running the <code>readstore configure</code> the first time, a configuration file is created in your home directory (<code>~/.readstore/config</code>) to store your credentials and CLI configuration.</p> <p>The config file is created with user-excklusive read-/write permissions (<code>chmod 600</code>), please make sure to keep the file permissions restricted.</p> <p>You find more information on the configuration file below.</p>"},{"location":"readme/#installation","title":"Installation","text":"<p><code>pip3 install readstore-cli</code></p> <p>You can perform the install in a conda or venv virtual environment to simplify package management.</p> <p>A local install is also possible</p> <p><code>pip3 install --user readstore-cli</code></p> <p>Make sure that <code>~/.local/bin</code> is on your <code>$PATH</code> in case you encounter problems when starting the server.</p> <p>Validate the install by running</p> <p><code>readstore -v</code></p> <p>This should print the ReadStore CLI version</p>"},{"location":"readme/#readstore-api","title":"ReadStore API","text":"<p>The ReadStore Basic server provides a RESTful API for accessing resources via HTTP requests. This API extends the functionalities of the ReadStore CLI as well as the Python and R SDKs.</p>"},{"location":"readme/#api-endpoint","title":"API Endpoint","text":"<p>By default, the API is accessible at: <code>http://127.0.0.1:8000/api_x_v1/</code></p>"},{"location":"readme/#authentication","title":"Authentication","text":"<p>Users must authenticate using their username and token via the Basic Authentication scheme.</p>"},{"location":"readme/#example-usage","title":"Example Usage","text":"<p>Below is an example demonstrating how to use the ReadStore CLI to retrieve an overview of Projects by sending an HTTP <code>GET</code> request to the <code>project/</code> endpoint. In this example, the username is <code>testuser</code>, and the token is <code>0dM9qSU0Q5PLVgDrZRftzw</code>. You can find your token in the ReadStore settings.</p> <pre><code>curl -X GET -u testuser:0dM9qSU0Q5PLVgDrZRftzw http://localhost:8000/api_x_v1/project/\n</code></pre>"},{"location":"readme/#example-reponse","title":"Example Reponse","text":"<p>A successful HTTP response returns a JSON-formatted string describing the project(s) in the ReadStore database. Example response:</p> <pre><code>[{\n  \"id\": 4,\n  \"name\": \"TestProject99\",\n  \"metadata\": {\n    \"key1\": \"value1\",\n    \"key2\": \"value2\"\n  },\n  \"attachments\": []\n}]\n</code></pre>"},{"location":"readme/#documentation","title":"Documentation","text":"<p>Comprehensive API documentation is available in the ReadStore Basic Docs.</p>"},{"location":"readme/#usage","title":"Usage","text":"<p>Detailed tutorials, videos and explanations are found on YouTube or on the EVOBYTE blog.</p>"},{"location":"readme/#quickstart","title":"Quickstart","text":"<p>Let's upload some FASTQ files.</p>"},{"location":"readme/#1-configure-cli","title":"1. Configure CLI","text":"<p>Make sure you have the ReadStore CLI installed and a running ReadStore server with your user registered.</p> <ol> <li> <p>Run <code>readstore configure</code></p> </li> <li> <p>Enter your username and token</p> </li> <li>Select the default output of your CLI requests. You can choose between <code>text</code> outputs, comma-separated <code>csv</code> or <code>json</code>.</li> <li>Run <code>readstore configure list</code> and check if your credentials are correct. </li> </ol>"},{"location":"readme/#2-upload-files","title":"2. Upload Files","text":"<p>For uploading FASTQ files your User Account needs to have <code>Staging Permission</code>. If you can check this in the <code>Settings</code> page of your account. If you not have <code>Staging Permission</code>, ask the ReadStore Server Admin to grant you permission.</p> <p>Move to a folder that contains some FASTQ files</p> <p><code>readstore upload myfile_r1.fastq</code></p> <p>This will upload the file and run the QC check. You can select multiple files at once using the <code>*</code> wildcard. The fastq files need to have the default file endings <code>.fastq, .fastq.gz, .fq, .fq.gz</code>.</p> <p>You can also upload multiple FASTQ files from a template <code>.csv</code> file using the <code>import fastq</code> function. More information below.</p>"},{"location":"readme/#3-stage-files","title":"3. Stage Files","text":"<p>Login to the web app on your browser and move to the <code>Staging</code> page. Here you find a list of all FASTQ files that you just uploaded. For larger files, the QC step can take a while to complete.</p> <p>FASTQ files are grouped into Datasets which you can <code>Check In</code>. Checked In Datasets appear in the <code>Datasets</code> page and can be accessed by the CLI.</p> <p>Check the <code>Batch Check In</code> button to import several Dataset at once.</p>"},{"location":"readme/#4-access-datasets-via-the-cli","title":"4. Access Datasets via the CLI","text":"<p>The ReadStore CLI enables programmatic access to Datasets and FASTQ files. Some examples are:</p> <p><code>readstore dataset list</code>  List all FASTQ files</p> <p><code>readstore dataset get --id 25</code>  Get detailed view on Dataset 25</p> <p><code>readstore dataset get --id 25 --read1-path</code>  Get path for Read1 FASTQ file</p> <p><code>readstore dataset get --id 25 --meta</code>  Get metadata for Dataset 25</p> <p><code>readstore project get --name cohort1 --attachment</code>  Get attachment files for Project \"cohort1\"</p> <p>You can find a full list of CLI commands below.</p>"},{"location":"readme/#5-managing-processed-data","title":"5. Managing Processed Data","text":"<p>Processed Data refer to files generated through processing of raw sequencing data. Depending on the omics technology and assay used, this could be for instance transcript count files, variant files or gene count matrices. </p> <p><code>readstore pro-data upload -d test_dataset_1 -n test_dataset_count_matrix -t count_matrix test_count_matrix.h5</code> Upload count matrix test_count_matrix.h5 with name \"test_dataset_count_matrix\" for dataset with name \"test_dataset_1\"</p> <p><code>readstore pro-data list</code> List Processed Data for all Datasets and Projects</p> <p><code>readstore pro-data get -d test_dataset_1 -n test_dataset_count_matrix</code> Get ProData details for Dataset \"test_dataset_1\" with the name \"test_dataset_count_matrix\"</p> <p><code>readstore pro-data delete -d test_dataset_1 -n test_dataset_count_matrix</code> Delete ProData for dataset \"test_dataset_1\" with the name \"test_dataset_count_matrix\"</p> <p>The delete operation does not remove the file from the file system, only from the database. A user needs <code>Staging Permission</code> to create or remove datasets.</p>"},{"location":"readme/#cli-configuration_1","title":"CLI Configuration","text":"<p><code>readstore configure</code> manages the CLI configuration. To setup the configuration:</p> <ol> <li> <p>Run <code>readstore configure</code></p> </li> <li> <p>Enter your username and token</p> </li> <li>Select the default output of your CLI requests. You can choose between <code>text</code> outputs, comma-separated <code>csv</code> or <code>json</code>.</li> <li>Run <code>readstore configure list</code> and check if your credentials are correct. </li> </ol> <p>If you already have a configuration in place, the CLI will ask whether you want to overwrite the existing credentials. Select <code>y</code> if yes.</p> <p>After running the <code>readstore configure</code> the first time, a configuration file is created in your home directory (<code>~/.readstore/config</code>). The config file is created with user-excklusive read-/write permissions (<code>chmod 600</code>), please make sure to keep the file permissions restricted.</p> <pre><code>[general]\nendpoint_url = http://localhost:8000\nfastq_extensions = ['.fastq', '.fastq.gz', '.fq', '.fq.gz']\noutput = csv\n\n[credentials]\nusername = myusername\ntoken = myrandomtoken\n</code></pre> <p>You can further edit the configuration of the CLI client from this configuration file. In case your ReadStore Django server is not run at the default port 8000, you need to update the <code>endpoint_url</code>. If you need to process FASTQ files with file endings other than those listed in <code>fastq_extensions</code>, you can modify the list.</p>"},{"location":"readme/#upload-fastq-files","title":"Upload FASTQ Files","text":"<p>For uploading FASTQ files your User Account needs to have <code>Staging Permission</code>. You can check this in the <code>Settings</code> page of your account. If you do not have <code>Staging Permission</code>, ask the ReadStore Server Admin to grant you permission.</p> <p><code>readstore upload myfile_r1.fastq myfile_r2.fastq ...</code></p> <p>This will upload the files and run the QC check. You can select several files at once using the <code>*</code> wildcard. It can take some time before FASTQ files are available in your <code>Staging</code> page depending on how large file are and how long the QC step takes.</p> <pre><code>usage: readstore upload [options]\n\nUpload FASTQ Files\n\npositional arguments:\n  fastq_files  FASTQ Files to Upload\n</code></pre>"},{"location":"readme/#import-fastq-files-from-csv-template","title":"Import FASTQ files from .csv Template","text":"<p>Import FASTQ files from template .csv file.</p> <p>A <code>.csv</code> file can be downloaded from the ReadStore App in the <code>Staging</code> Page or from this repository,  or is available in this repository under assets/readstore_template.csv</p> <p>The template .csv file must contain the columns <code>FASTQFileName</code>,<code>ReadType</code> &amp;    <code>UploadPath</code>.</p> <ul> <li>FASTQFileName Name for the FASTQ File in ReadStore DB</li> <li>ReadType FASTQ Read Type: R1 (Read 1), R2 (Read 2), I1 (Index 1) or I2 (Index 2)</li> <li>Upload Path File path to FASTQ file. Must be accessible from ReadStore server</li> </ul> <pre><code>usage: readstore import fastq [options]\n\nImport FASTQ Files\n\npositional arguments:\n  fastq_template  FASTQ Template .csv File\n</code></pre>"},{"location":"readme/#access-and-create-projects","title":"Access and Create Projects","text":"<p>There are 3 commands for accessing projects and related data and 2 commands for creating and updating projects</p> <ul> <li><code>list</code> provides an overview of project, metadata and attachments</li> <li><code>get</code> provides detailed information on individual projects and to its metadata and attachments</li> <li><code>download</code> lets you download attachment files of a project from the ReadStore database</li> <li><code>create</code> lets you create an empty project from the command line</li> <li><code>update</code> lets you update project attributes</li> </ul>"},{"location":"readme/#readstore-project-list","title":"readstore project list","text":"<pre><code>usage: readstore project ls [options]\n\nList Projects\n\noptions:\n  -h, --help            show this help message and exit\n  -m, --meta            Get Metadata\n  -a, --attachment      Get Attachment\n  --output {json,text,csv}\n                        Format of command output (see config for default)\n</code></pre> <p>Show project id and name.</p> <p>The <code>-m/--meta</code> include metadata for projects as json string in output.</p> <p>The <code>-a/--attachment</code> include attachment names as list in output.</p> <p>Adapt the output format of the command using the <code>--output</code> options.</p>"},{"location":"readme/#readstore-project-get","title":"readstore project get","text":"<pre><code>usage: readstore project get [options]\n\nGet Project\n\noptions:\n  -h, --help            show this help message and exit\n  -id , --id            Get Project by ID\n  -n , --name           Get Project by name\n  -m, --meta            Get only Metadata\n  -a, --attachment      Get only Attachment\n  --output {json,text,csv}\n                        Format of command output (see config for default)\n</code></pre> <p>Show project details for a project selected either by <code>--id</code> or the <code>--name</code> argument. The project details include description, date of creation, attachments and metadata</p> <p>The <code>-m/--meta</code> shows only the metadata with keys in header.</p> <p>The <code>-a/--attachment</code> shows only the attachments.</p> <p>Adapt the output format of the command using the <code>--output</code> options.</p> <p>Example: <code>readstore project get --id 2</code></p>"},{"location":"readme/#readstore-project-download","title":"readstore project download","text":"<pre><code>usage: readstore project download [options]\n\nDownload Project Attachments\n\noptions:\n  -h, --help          show this help message and exit\n  -id , --id          Select Project by ID\n  -n , --name         Select Project by name\n  -a , --attachment   Set Attachment Name to download\n  -o , --outpath      Download path or directory (default . )\n</code></pre> <p>Download attachment files for a project. Select a project selected either by <code>--id</code> or the <code>--name</code> argument.</p> <p>With the <code>--attachment</code> argument you specify the name of the attachment file to download.</p> <p>Use the <code>--outpath</code> to set a directory to download files to.</p> <p>Example <code>readstore project download --id 2 -a ProjectQC.pptx -o ~/downloads</code></p>"},{"location":"readme/#readstore-project-create","title":"readstore project create","text":"<pre><code>usage: readstore project create [options]\n\nCreate Project\n\noptions:\n  -h, --help            show this help message and exit\n  -n , --name           Project Name\n  --description         Set Description (default '')\n  -m META, --meta META  Set metadata as JSON string (e.g '{\"key\": \"value\"}') (default '{}')\n</code></pre> <p>Create a new project.</p> <p><code>-n/--name</code> name for new project (required)</p> <p><code>--description</code> project description. Defaults to empty</p> <p><code>-m/--meta</code> enables to set metadata for the project (optional). This attribute must be a json-formatted string, e.g. '{\"key\": \"value\"}'. Defaults to empty dictionary (<code>'{}'</code>)</p> <p>Example <code>readstore project create -n TestProject --description \"My First Test Project\" --meta '{\"cost_center\" : \"A1526\"}'</code></p>"},{"location":"readme/#readstore-project-update","title":"readstore project update","text":"<pre><code>usage: readstore project update [options]\n\nUpdate Project\n\noptions:\n  -h, --help            show this help message and exit\n  -id , --id            Project ID to select\n  -n , --name           Project Name (optional)\n  --description         Set Description (optional)\n  -m META, --meta META  Set metadata as JSON string (e.g '{\"key\": \"value\"}') (optional)\n\n</code></pre> <p>The project to update must be selected by its <code>id</code>. Attributes which are optional and not specified remain unchanged.</p> <p><code>-n/--name</code> name for project to update (optional)</p> <p><code>--description</code> project description to update (optional)</p> <p><code>-m/--meta</code> enables to update metadata for the project (optional). This attribute must be a json-formatted string, e.g. '{\"key\": \"value\"}'</p> <p>Example <code>readstore project update -id 1 -n UpdateTestProject --description \"My updated First Test Project\" --meta '{\"cost_center_update\" : \"A1526\"}'</code></p>"},{"location":"readme/#access-datasets-and-fastq-files","title":"Access Datasets and FASTQ Files","text":"<p>There are 3 commands for accessing dataset, and 2 commands for update and create operations.</p> <ul> <li><code>list</code> provides an overview of datasets, metadata and attachments</li> <li><code>get</code> provides detailed information on an individual dataset and to its metadata and attachments and individual FASTQ read files and statistics.</li> <li><code>download</code> lets you download attachment files of a dataset</li> <li><code>create</code> lets you create an empty dataset from the command line and assign to a project</li> <li><code>update</code> lets you update dataset attributes</li> </ul>"},{"location":"readme/#readstore-dataset-list","title":"readstore dataset list","text":"<pre><code>usage: readstore dataset ls [options]\n\nList FASTQ Datasets\n\noptions:\n  -h, --help            show this help message and exit\n  -p , --project-name   Subset by Project Name\n  -pid , --project-id   Subset by Project ID\n  -m, --meta            Get Metadata\n  -a, --attachment      Get Attachment\n  --output {json,text,csv}\n                        Format of command output (see config for default)\n</code></pre> <p>Show dataset id, name, description, qc_passed, paired_end, index_read, project_ids and project_names</p> <p><code>-p/--project-name</code> subset dataset from a specified project</p> <p><code>-pid/--project-id</code> subset dataset from a specified project</p> <p><code>-m/--meta</code> include metadata for datasets</p> <p><code>-a/--attachment</code> include attachment names as list for datasets</p> <p>Adapt the output format of the command using the <code>--output</code> options.</p>"},{"location":"readme/#readstore-dataset-get","title":"readstore dataset get","text":"<pre><code>usage: readstore dataset get [options]\n\nGet FASTQ Datasets and Files\n\noptions:\n  -h, --help            show this help message and exit\n  -id , --id            Get Dataset by ID\n  -n , --name           Get Dataset by name\n  -m, --meta            Get only Metadata\n  -a, --attachment      Get only Attchments\n  -r1, --read1          Get Read 1 Data\n  -r2, --read2          Get Read 2 Data\n  -r1p, --read1-path    Get Read 1 FASTQ Path\n  -r2p, --read2-path    Get Read 2 FASTQ Path\n  -i1, --index1         Get Index 1 Data\n  -i2, --index2         Get Index 2 Data\n  -i1p, --index1-path   Get Index 1 FASTQ Path\n  -i2p, --index2-path   Get Index 2 FASTQ Path\n  --output {json,text,csv}\n                        Format of command output (see config for default)\n\n</code></pre> <p>Show details for a dataset selected either by <code>--id</code> or the <code>--name</code> argument.</p> <p><code>-m/--meta</code> shows only the metadata with keys in header.</p> <p><code>-a/--attachment</code> shows only the attachments.</p> <p><code>-r1/--read1</code> shows details for dataset Read 1 data (same for <code>--read2</code>, <code>--index1</code>, <code>--index2</code>)</p> <p><code>-r1p/--read1-path</code> returns path for dataset Read 1 (same for <code>--read2-path</code>, <code>--index1-path</code>, <code>--index2-path</code>)</p> <p>Adapt the output format of the command using the <code>--output</code> options.</p> <p>Example: <code>readstore get --id 2</code></p> <p>Example: <code>readstore get --id 2 --read1-path</code></p>"},{"location":"readme/#readstore-dataset-download","title":"readstore dataset download","text":"<pre><code>usage: readstore dataset download [options]\n\nDownload Dataset attachments\n\noptions:\n  -h, --help          show this help message and exit\n  -id , --id          Select Dataset by ID\n  -n , --name         Select Dataset by name\n  -a , --attachment   Set Attachment Name to download\n  -o , --outpath      Download path or directory (default . )\n</code></pre> <p>Download attachment files for a dataset. Select dataset either by <code>--id</code> or the <code>--name</code> argument.</p> <p>With the <code>--attachment</code> argument you specify the name of the attachment file to download.</p> <p>Use the <code>--outpath</code> to set a directory to download files to.</p> <p>Example <code>readstore download --id 2 -a myAttachment.csv -o ~/downloads</code></p>"},{"location":"readme/#readstore-dataset-create","title":"readstore dataset create","text":"<pre><code>usage: readstore dataset create [options]\n\nCreate a Dataset\n\noptions:\n  -h, --help            show this help message and exit\n  -n , --name           Dataset Name\n  --description         Set Description (default '')\n  -m META, --meta META  Set metadata as JSON string (e.g '{\"key\": \"value\"}') (default '{}')\n  -pid , --project-id   Set Project ID (optional)\n  -p , --project-name   Set Project Name (optional)\n</code></pre> <p>Create an empty dataset. </p> <p><code>-n/--name</code> name for new project (required)</p> <p><code>--description</code> project description. Defaults to empty</p> <p><code>-m/--meta</code> enables to set metadata for the project (optional). This attribute must be a json-formatted string, e.g. '{\"key\": \"value\"}'. Defaults to empty dictionary (<code>'{}'</code>)</p> <p><code>-pid/--project-id</code> enables to attach dataset to a project defined by project id (optional)</p> <p><code>-p/--project-name</code> enables to attach dataset to a project defined by project name (optional)</p> <p>Example <code>readstore dataset create -n Dataset1 --description \"A Dataset\" --meta '{\"replicate\" : 1}' -p TestProject</code></p>"},{"location":"readme/#readstore-dataset-update","title":"readstore dataset update","text":"<pre><code>usage: readstore dataset update [options]\n\nUpdate a Dataset\n\noptions:\n  -h, --help            show this help message and exit\n  -id , --id            Dataset ID to select\n  -n , --name           Dataset Name (optional)\n  --description         Set Description (default '') (optional)\n  -m META, --meta META  Set metadata as JSON string (e.g '{\"key\": \"value\"}') (optional)\n  -pid , --project-id   Set Project ID (optional)\n  -p , --project-name   Set Project Name (optional)\n</code></pre> <p>The dataset to update must be selected by its <code>id</code>. Attributes which are optional and not specified remain unchanged.</p> <p><code>-n/--name</code> name for dataset to update (optional)</p> <p><code>--description</code> dataset description to update (optional)</p> <p><code>-m/--meta</code> enables to update metadata for the project (optional). This attribute must be a json-formatted string, e.g. '{\"key\": \"value\"}'</p> <p><code>-pid/--project-id</code> update project the dataset is attached to by its project id (optional)</p> <p><code>-p/--project-name</code> update project the dataset is attached to by its project name (optional)</p> <p>Example <code>readstore dattaset update -id 1 -n UpdateName --meta '{\"replicate_update\" : \"1\"}' -pid 12</code></p>"},{"location":"readme/#access-processed-data","title":"Access Processed Data","text":"<p>There are 4 commands for accessing ProData, <code>readstore  pro-data upload</code>, <code>pro-data get</code> and <code>pro-data list</code> and <code>readstore pro-data delete</code>.</p> <ul> <li> <p><code>upload</code> lets you create new ProData entries for a specifies dataset</p> </li> <li> <p><code>list</code> provides an overview of ProData entries for Projects or Datasets</p> </li> <li><code>get</code> provides detailed information on an individual ProData entry and to its metadata.</li> <li><code>delete</code> remove ProData entries</li> </ul>"},{"location":"readme/#readstore-pro-data-upload","title":"readstore pro-data upload","text":"<pre><code>usage: readstore pro-data upload [options]\n\nUpload Processed Data\n\npositional arguments:\n  pro_data_file         Path to Processed Data File to Upload\n\noptions:\n  -h, --help            show this help message and exit\n  -did , --dataset-id   Set associated Dataset by ID\n  -d , --dataset-name   Set associated Dataset by Name\n  -n , --name           Set Processed Data Name (required)\n  -t , --type           Set Type of Processed Data (e.g. gene_counts) (required)\n  --description         Set Description\n  -m META, --meta META  Set metadata as JSON string (e.g '{\"key\": \"value\"}')\n</code></pre> <p>Upload Processed Data to ReadStore database and connect with an existing dataset.</p> <p>Processed Data can be any file type and tyically represent datasets for downstream omics analysis, for instance gene count matrices or variant files.</p> <p>Your ReadStore user account is required to have <code>Staging Permissions</code> to upload or delete Processed Data.</p> <p>You need to specify a <code>--dataset-id</code> or <code>--dataset-name</code> to select the dataset to attach files to.</p> <p><code>-n/--name</code> defines the name to set for the processed data in the ReadStore DB</p> <p><code>-t/--type</code> defines the data type of the processed dataset. The type is free to choose, for instance <code>gene_counts</code> or <code>count_matrix</code></p> <p><code>-m/--meta</code> enables to set metadata for the processed data (optional). This attribute must be a json-formatted string, e.g. <code>'{\"key\": \"value\"}'</code></p> <p><code>--description</code> set a optional description for the dataset (optional).</p> <p>Example: <code>readstore pro-data upload -d test_dataset_1 -n test_dataset_count_matrix -t count_matrix -m '{\"key\":\"value\"}' test_count_matrix.h5</code></p>"},{"location":"readme/#readstore-pro-data-list","title":"readstore pro-data list","text":"<pre><code>usage: readstore pro-data list [options]\n\nList Processed Data\n\noptions:\n  -h, --help            show this help message and exit\n  -pid , --project-id   Subset by Project ID\n  -p , --project-name   Subset by Project Name\n  -did , --dataset-id   Subset by Dataset ID\n  -d , --dataset-name   Subset by Dataset Name\n  -n , --name           Subset by ProData Name\n  -t , --type           Subset by Data Type\n  -m, --meta            Get Metadata\n  -a, --archived        Include Archived ProData\n  --output {json,text,csv}\n                        Format of command output (see config for default)\n</code></pre> <p>List Processed Data stored in the ReadStore database.</p> <p>You can subset the list by Projects (<code>-pid/-p</code>), Datasets (<code>-did/-d</code>) and/or by the specific Name (<code>-n</code>) of the Processed Data stored.</p> <p><code>-m/--meta</code> Also show metadata</p> <p><code>-a/--archived</code> Show archived Processed Data.</p> <p>Processed Data are archived when a new file with the same name attribute is uploaded. This invalidates a previous version of the Processed Data</p> <p>Example: <code>readstore pro-data list -p TestProject</code></p>"},{"location":"readme/#readstore-pro-data-get","title":"readstore pro-data get","text":"<pre><code>usage: readstore pro-data get [options]\n\nGet Processed Data\n\noptions:\n  -h, --help            show this help message and exit\n  -id , --id            Get ProData by ID\n  -did , --dataset-id   Get ProData by Dataset ID\n  -d , --dataset-name   Get ProData by Dataset Name\n  -n , --name           Get ProData by Name\n  -m, --meta            Get only Metadata\n  -p, --upload-path     Get only Upload Path\n  -v , --version        Get ProData Version (default: latest)\n  --output {json,text,csv}\n                        Format of command output (see config for default)\n</code></pre> <p>Get single Processed Data by their <code>-id</code> or the associated <code>--dataset-id/--dataset-name</code> plus <code>--name</code> argument.</p> <p><code>-m/--meta</code> Return only metadata</p> <p><code>-p/--upload-path</code> Return only upload path</p> <p><code>-v/--version</code> Select ProData by specific version (Optional). Default: latest version.</p> <p>Example: <code>readstore pro-data get -d test_dataset_1 -n test_dataset_count_matrix</code></p>"},{"location":"readme/#readstore-pro-data-delete","title":"readstore pro-data delete","text":"<pre><code>usage: readstore pro-data delete [options]\n\nDelete Processed Data\n\noptions:\n  -h, --help            show this help message and exit\n  -id , --id            Delete ProData by ID\n  -did , --dataset-id   Delete ProData by Dataset ID\n  -d , --dataset-name   Delete ProData by Dataset Name\n  -n , --name           Delete ProData by Name\n  -v , --version        Delete ProData Version (default: latest)\n</code></pre> <p>Delete Processed Data by their <code>-id</code> or the associated <code>--dataset-id / --dataset-name</code> plus <code>--name</code> argument.</p> <p><code>-v/--version</code> Delete ProData by specific version (Optional). Default: latest version.</p> <p>Example: <code>readstore pro-data delete -d test_dataset_1 -n test_dataset_count_matrix</code></p>"},{"location":"readme/#contributing","title":"Contributing","text":"<p>Contributions make this project better! Whether you want to report a bug, improve documentation, or add new features, any help is welcomed!</p>"},{"location":"readme/#how-you-can-help","title":"How You Can Help","text":"<ul> <li>Report Bugs</li> <li>Suggest Features</li> <li>Improve Documentation</li> <li>Code Contributions</li> </ul>"},{"location":"readme/#contribution-workflow","title":"Contribution Workflow","text":"<ol> <li>Fork the repository and create a new branch for each contribution.</li> <li>Write clear, concise commit messages.</li> <li>Submit a pull request and wait for review.</li> </ol> <p>Thank you for helping make this project better!</p>"},{"location":"readme/#license","title":"License","text":"<p>The ReadStore CLI is licensed under an Apache 2.0 Open Source License. See the LICENSE file for more information.</p>"},{"location":"readme/#credits-and-acknowledgments","title":"Credits and Acknowledgments","text":"<p>ReadStore CLI is built upon the following open-source python packages and would like to thank all contributing authors, developers and partners.</p> <ul> <li>Python (https://www.python.org/)</li> <li>Requests (https://requests.readthedocs.io/en/latest/)</li> </ul>"},{"location":"reference/readstore/","title":"readstore-cli package","text":""},{"location":"reference/readstore/#readstore-module","title":"readstore module","text":"<p>Provides readstore command line interface</p> <p>Functions:</p> Name Description <code>- configure_list</code> <p>List configuration settings</p> <code>- configure</code> <p>Configure ReadStore CLI</p> <code>- upload</code> <p>Upload FASTQ Files</p> <code>- import_fastq</code> <p>Import FASTQ Files from Template</p> <code>- upload_pro_data</code> <p>Upload Processed Data</p> <code>- list_fq_datasets</code> <p>List Datasets</p> <code>- list_projects</code> <p>List Projects</p> <code>- list_pro_data</code> <p>List Processed Data</p> <code>- get_fastq_dataset</code> <p>Get Dataset</p> <code>- get_project</code> <p>Get Project</p> <code>- get_pro_data</code> <p>Get Processed Data</p> <code>- create_fastq_dataset</code> <p>Create Dataset</p> <code>- create_project</code> <p>Create Project</p> <code>- update_fq_dataset</code> <p>Update Dataset</p> <code>- update_project</code> <p>Update Project</p> <code>- delete_pro_data</code> <p>Delete Processed Data</p> <code>- download_fq_dataset_attachment</code> <p>Download Dataset Attachment</p> <code>- download_project_attachment</code> <p>Download Project Attachment</p> <code>- main</code> <p>Main function for ReadStore CLI</p>"},{"location":"reference/readstore/#readstore_cli.readstore._get_readstore_client","title":"<code>_get_readstore_client()</code>","text":"<p>Get ReadStore RSClient</p> <p>Load readstore configuration and generate client Requires READSTORE_CONFIG_FILE global Requires DEFAULT_ENDPOINT_URL Requires DEFAULT_FASTQ_EXTENSIONS Requires DEFAULT_OUTPUT</p> <p>Raises:</p> Type Description <code>ReadStoreError</code> <p>If no config is found in config file or ENV variables</p> <p>Returns:</p> Type Description <code>RSClient</code> <p>rsclient.RSClient</p> Source code in <code>readstore_cli/readstore.py</code> <pre><code>def _get_readstore_client() -&gt; rsclient.RSClient:\n    \"\"\"Get ReadStore RSClient\n\n    Load readstore configuration and generate client\n    Requires READSTORE_CONFIG_FILE global\n    Requires DEFAULT_ENDPOINT_URL\n    Requires DEFAULT_FASTQ_EXTENSIONS\n    Requires DEFAULT_OUTPUT\n\n    Raises:\n        rsexceptions.ReadStoreError:\n            If no config is found in config file or ENV variables\n\n    Returns:\n        rsclient.RSClient\n    \"\"\"\n\n    if os.path.isfile(READSTORE_CONFIG_FILE):\n        config_params = rsconfig.load_rs_config(filename=READSTORE_CONFIG_FILE)\n    else:\n        try:\n            # Try to load default configuration and environment variables\n            config_params = rsconfig.load_rs_config(\n                default_endpoint_url=DEFAULT_ENDPOINT_URL,\n                default_fastq_extensions=DEFAULT_FASTQ_EXTENSIONS,\n                default_output=DEFAULT_OUTPUT,\n            )\n\n        except rsexceptions.ReadStoreError as e:\n            raise rsexceptions.ReadStoreError(\n                e.message + \"\\n No Configuration File and No ENV Variables Found\"\n            )\n\n    username, token, endpoint_url, fastq_extensions, output = config_params\n\n    client = rsclient.RSClient(username, token, endpoint_url, output)\n\n    return client\n</code></pre>"},{"location":"reference/readstore/#readstore_cli.readstore._validate_read_path","title":"<code>_validate_read_path(fq_file_path)</code>","text":"<p>Check fq_file path</p> <p>Check if fastq file exists and can be read</p> <p>Parameters:</p> Name Type Description Default <code>fq_file_path</code> <code>str</code> <p>File to check</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if path is valid else False</p> Source code in <code>readstore_cli/readstore.py</code> <pre><code>def _validate_read_path(fq_file_path: str) -&gt; bool:\n    \"\"\"Check fq_file path\n\n    Check if fastq file exists and can be read\n\n    Args:\n        fq_file_path: File to check\n\n    Returns:\n        bool: True if path is valid else False\n    \"\"\"\n\n    # Check if file exists\n    if not os.path.isfile(fq_file_path):\n        sys.stderr.write(\n            f\"\"\"ReadStore Warning:\n            Upload Path of this FASTQ File could not be found: {fq_file_path}\\n\"\"\"\n        )\n        return False\n    # Check for read permission\n    elif not os.access(fq_file_path, os.R_OK):\n        sys.stderr.write(f\"ReadStore Warning: No Read Permission: {fq_file_path}\\n\")\n        return False\n    else:\n        return True\n</code></pre>"},{"location":"reference/readstore/#readstore_cli.readstore.configure","title":"<code>configure()</code>","text":"<p>Configure CLI</p> <p>Write config file for ReadStore CLI</p> <p>Requires: READSTORE_CONFIG_FILE</p> <p>Write config file to READSTORE_CONFIG_FILE</p> Source code in <code>readstore_cli/readstore.py</code> <pre><code>def configure():\n    \"\"\"Configure CLI\n\n    Write config file for ReadStore CLI\n\n    Requires: READSTORE_CONFIG_FILE\n\n    Write config file to READSTORE_CONFIG_FILE\n\n    \"\"\"\n\n    print(\"Configuring ReadStore CLI\")\n\n    readstore_config_dir = os.path.dirname(READSTORE_CONFIG_FILE)\n\n    os.makedirs(readstore_config_dir, exist_ok=True)\n\n    username = input(\"ReadStore Username: \")\n    token = input(\"ReadStore Token: \")\n    output = input(\"Default Output Format (json, text, csv): \")\n\n    if output not in OUTPUT_FORMATS:\n        sys.stderr.write(\"ReadStore Error: Invalid Output Format.\\n\")\n        return\n\n    endpoint_url = DEFAULT_ENDPOINT_URL\n    fastq_extensions = DEFAULT_FASTQ_EXTENSIONS\n    write_config = True\n\n    # Check if config exists, if so, ask to overwrite\n    if os.path.isfile(READSTORE_CONFIG_FILE):\n\n        try:\n            config = rsconfig.load_rs_config(READSTORE_CONFIG_FILE)\n            (\n                username_old,\n                token_old,\n                endpoint_url_old,\n                fastq_extensions_old,\n                output_format_old,\n            ) = config\n            write_config = False\n            print(f\"Config file found at {READSTORE_CONFIG_FILE}\")\n            overwrite = input(\"Overwrite? (y/n): \")\n\n            # If not overwrite, don't write config\n            if overwrite.lower().strip() == \"y\":\n\n                endpoint_url = endpoint_url_old\n                fastq_extensions = fastq_extensions_old\n                rsconfig.write_rs_config(\n                    READSTORE_CONFIG_FILE,\n                    username,\n                    token,\n                    endpoint_url,\n                    fastq_extensions,\n                    output,\n                )\n                print(\"Configuration File Updated\")\n            else:\n                print(\"Abort Configuration\")\n\n        except rsexceptions.ReadStoreError:\n            # If config file is invalid, overwrite anyway\n            sys.stderr.write(\"Error Setting Configuration\\n\")\n\n    if write_config:\n\n        rsconfig.write_rs_config(\n            READSTORE_CONFIG_FILE,\n            username,\n            token,\n            endpoint_url,\n            fastq_extensions,\n            output,\n        )\n        print(f\"Created New Configuration File at {READSTORE_CONFIG_FILE}\")\n</code></pre>"},{"location":"reference/readstore/#readstore_cli.readstore.configure_list","title":"<code>configure_list()</code>","text":"<p>List config settings</p> <p>List user and general client configuration Print in console</p> <p>Raises: rsexceptions.ReadStoreError</p> Source code in <code>readstore_cli/readstore.py</code> <pre><code>def configure_list():\n    \"\"\"List config settings\n\n    List user and general client configuration\n    Print in console\n\n\n\n    Raises: rsexceptions.ReadStoreError\n    \"\"\"\n\n    print(\"Listing ReadStore Configuration and Credentials\")\n\n    if os.path.isfile(READSTORE_CONFIG_FILE):\n        try:\n            config_params = rsconfig.load_rs_config(READSTORE_CONFIG_FILE)\n            username, token, endpoint_url, fastq_extensions, output = config_params\n\n            # For token make last 4 characters visible\n            token_hidden = \"*\" * (len(token) - 4) + token[-4:]\n\n            print(f\"Configuration File Found at {READSTORE_CONFIG_FILE}\")\n\n            print(\"[USER]\")\n            print(f\"Username: {username}\")\n            print(f\"Token: {token_hidden}\")\n\n            print(\"[GENERAL]\")\n            print(f\"Endpoint URL: {endpoint_url}\")\n            print(f\"\"\"FASTQ Extensions: {fastq_extensions}\"\"\")\n            print(f\"\"\"Default Output: {output}\"\"\")\n\n        except rsexceptions.ReadStoreError as e:\n            # If config file is invalid, overwrite anyway\n            sys.stderr.write(e.message + \"\\n\")\n            sys.stderr.write(\n                \"\"\"Configuration Found, But Corrupted.\\n\n                             Reset Configuration with \"readstore configure\"\\n\"\"\"\n            )\n    else:\n        sys.stderr.write(\n            \"\"\"No Configuration Found.\\n\n                        Set Configuration with \"readstore configure\"\\n\"\"\"\n        )\n</code></pre>"},{"location":"reference/readstore/#readstore_cli.readstore.download_fq_dataset_attachment","title":"<code>download_fq_dataset_attachment(attachment_name, outpath, dataset_id=None, dataset_name=None)</code>","text":"<p>Download Fastq Dataset Attachment</p> <p>Parameters:</p> Name Type Description Default <code>attachment_name</code> <code>str</code> <p>Choose attachment to download</p> required <code>outpath</code> <code>str</code> <p>Set outpath to write file to.</p> required <code>dataset_id</code> <code>int | None</code> <p>Set dataset id</p> <code>None</code> <code>dataset_name</code> <code>str | None</code> <p>Set dataset name</p> <code>None</code> Source code in <code>readstore_cli/readstore.py</code> <pre><code>def download_fq_dataset_attachment(\n    attachment_name: str,\n    outpath: str,\n    dataset_id: int | None = None,\n    dataset_name: str | None = None,\n):\n    \"\"\"Download Fastq Dataset Attachment\n\n    Args:\n        attachment_name: Choose attachment to download\n        outpath: Set outpath to write file to.\n        dataset_id: Set dataset id\n        dataset_name: Set dataset name\n    \"\"\"\n\n    if not dataset_id and not dataset_name:\n        sys.stderr.write(\n            \"ReadStore Error: Must Provide Dataset ID (--id) or Name (--name)\\n\"\n        )\n        sys.stderr.write(\"ReadStore Error: Run readstore download -h for help\\n\")\n        return\n\n    # Get ReadStore Client and Validate Connection\n    try:\n        client = _get_readstore_client()\n    except rsexceptions.ReadStoreError as e:\n        sys.stderr.write(f\"ReadStore Error: {e.message}\\n\")\n        return\n\n    outpath = os.path.abspath(outpath)\n    out_dirname = os.path.dirname(outpath)\n\n    # case directory path (e.g. '.' or /home/user/)\n    if os.path.isdir(outpath):\n        download_path = os.path.join(outpath, attachment_name)\n    # case full path is provided, e.g. test.png or /home/user/test.png\n    elif os.path.isdir(out_dirname):\n        download_path = outpath\n    else:\n        sys.stderr.write(\n            f\"ReadStore Error: Output Directory Path Not Found: {outpath}\\n\"\n        )\n        return\n\n    try:\n        client.download_fq_dataset_attachment(\n            attachment_name=attachment_name,\n            outpath=download_path,\n            dataset_id=dataset_id,\n            dataset_name=dataset_name,\n        )\n\n        print(f\"ReadStore Download: {attachment_name}\\nDownloaded to {outpath}\")\n\n    except rsexceptions.ReadStoreError as e:\n        sys.stderr.write(f\"ReadStore Error: {e.message}\\n\")\n        return\n</code></pre>"},{"location":"reference/readstore/#readstore_cli.readstore.download_project_attachment","title":"<code>download_project_attachment(attachment_name, outpath, project_id=None, project_name=None)</code>","text":"<p>Download Project Attachment</p> <p>Download attachment file from project defined by project id or project name and download attachment_name</p> <p>Either project_id and project_name are required</p> <p>Parameters:</p> Name Type Description Default <code>attachment_name</code> <code>str</code> <p>Choose attachment to download</p> required <code>outpath</code> <code>str</code> <p>Set outpath to write file to.</p> required <code>project_id</code> <code>int | None</code> <p>Set project id</p> <code>None</code> <code>project_name</code> <code>str | None</code> <p>Set project name</p> <code>None</code> Source code in <code>readstore_cli/readstore.py</code> <pre><code>def download_project_attachment(\n    attachment_name: str,\n    outpath: str,\n    project_id: int | None = None,\n    project_name: str | None = None,\n):\n    \"\"\"Download Project Attachment\n\n    Download attachment file from project defined by project id\n    or project name and download attachment_name\n\n    Either project_id and project_name are required\n\n    Args:\n        attachment_name: Choose attachment to download\n        outpath: Set outpath to write file to.\n        project_id: Set project id\n        project_name: Set project name\n    \"\"\"\n\n    if not project_id and not project_name:\n        sys.stderr.write(\n            \"ReadStore Error: Must Provide Project ID (--id) or Name (--name)\\n\"\n        )\n        sys.stderr.write(\n            \"ReadStore Error: Run readstore project download -h for help\\n\"\n        )\n        return\n\n    # Get ReadStore Client and Validate Connection\n    try:\n        client = _get_readstore_client()\n    except rsexceptions.ReadStoreError as e:\n        sys.stderr.write(f\"ReadStore Error: {e.message}\\n\")\n        return\n\n    outpath = os.path.abspath(outpath)\n    out_dirname = os.path.dirname(outpath)\n\n    # case directory path (e.g. '.' or /home/user/)\n    if os.path.isdir(outpath):\n        download_path = os.path.join(outpath, attachment_name)\n    # case full path is provided, e.g. test.png or /home/user/test.png\n    elif os.path.isdir(out_dirname):\n        download_path = outpath\n    else:\n        sys.stderr.write(\n            f\"ReadStore Error: Output Directory Path Not Found: {outpath}\\n\"\n        )\n        return\n\n    try:\n        client.download_project_attachment(\n            attachment_name=attachment_name,\n            outpath=download_path,\n            project_id=project_id,\n            project_name=project_name,\n        )\n\n        print(f\"ReadStore Download: {attachment_name}\\nDownloaded to {outpath}\")\n\n    except rsexceptions.ReadStoreError as e:\n        sys.stderr.write(f\"ReadStore Error: {e.message}\\n\")\n        return\n</code></pre>"},{"location":"reference/readstore/#readstore_cli.readstore.get_fastq_dataset","title":"<code>get_fastq_dataset(dataset_id=None, dataset_name=None, meta=False, attachment=False, pro_data=False, read1=False, read2=False, index1=False, index2=False, read1_path=False, read2_path=False, index1_path=False, index2_path=False, output=None)</code>","text":"<p>Get individual FASTQ dataset</p> <p>Use arguments to filter and return specific data such as individual reads, metadata or read paths</p> <p>Parameters:</p> Name Type Description Default <code>dataset_id</code> <code>int | None</code> <p>Filter by Dataset Id. Defaults to None.</p> <code>None</code> <code>dataset_name</code> <code>str | None</code> <p>Filter by Dataset Name. Defaults to None.</p> <code>None</code> <code>meta</code> <code>bool</code> <p>Show only metadata.</p> <code>False</code> <code>attachment</code> <code>bool</code> <p>Show only attachments</p> <code>False</code> <code>read1</code> <code>bool</code> <p>Show Read 1 data.</p> <code>False</code> <code>read2</code> <code>bool</code> <p>Show Read 2 data.</p> <code>False</code> <code>index1</code> <code>bool</code> <p>Show Index 1 data</p> <code>False</code> <code>index2</code> <code>bool</code> <p>Show Index 2 data</p> <code>False</code> <code>read1_path</code> <code>bool</code> <p>Show Read 1 Path</p> <code>False</code> <code>read2_path</code> <code>bool</code> <p>Show Read 2 Path</p> <code>False</code> <code>index1_path</code> <code>bool</code> <p>Show Index 1 Path</p> <code>False</code> <code>index2_path</code> <code>bool</code> <p>Show Index 2 Path</p> <code>False</code> <code>output</code> <code>str | None</code> <p>Set output format. If none use default from config file</p> <code>None</code> Source code in <code>readstore_cli/readstore.py</code> <pre><code>def get_fastq_dataset(\n    dataset_id: int | None = None,\n    dataset_name: str | None = None,\n    meta: bool = False,\n    attachment: bool = False,\n    pro_data: bool = False,\n    read1: bool = False,\n    read2: bool = False,\n    index1: bool = False,\n    index2: bool = False,\n    read1_path: bool = False,\n    read2_path: bool = False,\n    index1_path: bool = False,\n    index2_path: bool = False,\n    output: str | None = None,\n):\n    \"\"\"Get individual FASTQ dataset\n\n    Use arguments to filter and return specific data\n    such as individual reads, metadata or read paths\n\n    Args:\n        dataset_id: Filter by Dataset Id. Defaults to None.\n        dataset_name: Filter by Dataset Name. Defaults to None.\n        meta: Show only metadata.\n        attachment: Show only attachments\n        read1: Show Read 1 data.\n        read2: Show Read 2 data.\n        index1: Show Index 1 data\n        index2: Show Index 2 data\n        read1_path: Show Read 1 Path\n        read2_path: Show Read 2 Path\n        index1_path: Show Index 1 Path\n        index2_path: Show Index 2 Path\n        output: Set output format. If none use default from config file\n    \"\"\"\n\n    if not dataset_id and not dataset_name:\n        sys.stderr.write(\n            \"ReadStore Error: Must Provide Dataset ID (--id) or Name (--name)\\n\"\n        )\n        sys.stderr.write(\"ReadStore Error: Run readstore get -h for help\\n\")\n        return\n\n    # Get ReadStore Client and Validate Connection\n    try:\n        client = _get_readstore_client()\n    except rsexceptions.ReadStoreError as e:\n        sys.stderr.write(f\"ReadStore Error: {e.message}\\n\")\n        return\n\n    if output is None:\n        output = client.get_output_format()\n\n    try:\n        fq_dataset = client.get_fastq_dataset(dataset_id, dataset_name)\n\n        path = False\n\n        # Check if dataset is empty\n        if fq_dataset == {}:\n            out_data = {}\n        elif meta:\n            out_data = fq_dataset.pop(\"metadata\", {})\n        elif attachment:\n            out_data = fq_dataset.pop(\"attachments\", {})\n            out_data = {\"name\": out_data}\n        elif pro_data:\n            out_data = fq_dataset.pop(\"pro_data\", {})\n            out_data = {\"pro_data\": out_data}\n\n        # Return individual read files\n        elif read1:\n            if fq_dataset[\"fq_file_r1\"]:\n                out_data = client.get_fq_file(fq_dataset[\"fq_file_r1\"])\n            else:\n                out_data = {}\n        elif read2:\n            if fq_dataset[\"fq_file_r2\"]:\n                out_data = client.get_fq_file(fq_dataset[\"fq_file_r2\"])\n            else:\n                out_data = {}\n        elif index1:\n            if fq_dataset[\"fq_file_i1\"]:\n                out_data = client.get_fq_file(fq_dataset[\"fq_file_i1\"])\n            else:\n                out_data = {}\n        elif index2:\n            if fq_dataset[\"fq_file_i2\"]:\n                out_data = client.get_fq_file(fq_dataset[\"fq_file_i2\"])\n            else:\n                out_data = {}\n        elif read1_path:\n            path = True\n            if fq_dataset[\"fq_file_r1\"]:\n                out_data = client.get_fq_file_upload_path(fq_dataset[\"fq_file_r1\"])\n                _ = _validate_read_path(out_data)\n            else:\n                out_data = \"\"\n        elif read2_path:\n            path = True\n            if fq_dataset[\"fq_file_r2\"]:\n                out_data = client.get_fq_file_upload_path(fq_dataset[\"fq_file_r2\"])\n                _ = _validate_read_path(out_data)\n            else:\n                out_data = \"\"\n        elif index1_path:\n            path = True\n            if fq_dataset[\"fq_file_i1\"]:\n                out_data = client.get_fq_file_upload_path(fq_dataset[\"fq_file_i1\"])\n                _ = _validate_read_path(out_data)\n            else:\n                out_data = \"\"\n        elif index2_path:\n            path = True\n            if fq_dataset[\"fq_file_i2\"]:\n                out_data = client.get_fq_file_upload_path(fq_dataset[\"fq_file_i2\"])\n                _ = _validate_read_path(out_data)\n            else:\n                out_data = \"\"\n        # Return individual read files\n        else:\n            # Reformat so that all data is in one dict\n            out_data = fq_dataset\n\n        if output == \"json\":\n            print(out_data)\n        elif output == \"text\":\n            if path:\n                print(out_data)\n            else:\n                header = list(out_data.keys())\n                header_str = \" | \".join(header)\n                print(header_str)\n\n                if attachment:\n                    values_str = \"\\n\".join(out_data[\"name\"])\n                else:\n                    values = [str(out_data[key]) for key in header]\n                    values_str = \" | \".join(values)\n                print(values_str)\n        elif output == \"csv\":\n            if path:\n                print(out_data)\n            else:\n                header = list(out_data.keys())\n                header_str = \",\".join(header)\n                print(header_str)\n\n                if attachment:\n                    values_str = \"\\n\".join(out_data[\"name\"])\n                else:\n                    values = [str(out_data[key]) for key in header]\n                    values_str = \",\".join(values)\n                print(values_str)\n        else:\n            sys.stderr.write(\"Output Format Not Supported\\n\")\n            return\n\n    except rsexceptions.ReadStoreError as e:\n        sys.stderr.write(f\"ReadStore Error: {e.message}\\n\")\n        return\n</code></pre>"},{"location":"reference/readstore/#readstore_cli.readstore.get_project","title":"<code>get_project(project_id=None, project_name=None, meta=False, attachment=False, output=None)</code>","text":"<p>Get individual Project</p> <p>Must define project id or name Options to show only meta and attachments</p> <p>Parameters:</p> Name Type Description Default <code>project_id</code> <code>int | None</code> <p>Set Project ID</p> <code>None</code> <code>project_name</code> <code>str | None</code> <p>Set Project Name</p> <code>None</code> <code>meta</code> <code>bool</code> <p>Show only meta data</p> <code>False</code> <code>attachment</code> <code>bool</code> <p>Show only attachments</p> <code>False</code> <code>output</code> <code>str | None</code> <p>Set output format. If none use default from config file</p> <code>None</code> Source code in <code>readstore_cli/readstore.py</code> <pre><code>def get_project(\n    project_id: int | None = None,\n    project_name: str | None = None,\n    meta: bool = False,\n    attachment: bool = False,\n    output: str | None = None,\n):\n    \"\"\"Get individual Project\n\n    Must define project id or name\n    Options to show only meta and attachments\n\n    Args:\n        project_id: Set Project ID\n        project_name: Set Project Name\n        meta: Show only meta data\n        attachment: Show only attachments\n        output: Set output format. If none use default from config file\n    \"\"\"\n\n    if not project_id and not project_name:\n        sys.stderr.write(\n            \"ReadStore Error: Must Provide Project ID (--id) or Name (--name)\\n\"\n        )\n        sys.stderr.write(\"ReadStore Error: Run readstore project get -h for help\\n\")\n        return\n\n    # Get ReadStore Client and Validate Connection\n    try:\n        client = _get_readstore_client()\n    except rsexceptions.ReadStoreError as e:\n        sys.stderr.write(f\"ReadStore Error: {e.message}\\n\")\n        return\n\n    if output is None:\n        output = client.get_output_format()\n\n    try:\n        project = client.get_project(project_id, project_name)\n\n        project.pop(\"dataset_metadata_keys\", None)\n\n        if meta:\n            out_data = project.pop(\"metadata\", {})\n        elif attachment:\n            out_data = project.pop(\"attachments\", {})\n            out_data = {\"name\": out_data}\n        else:\n            out_data = project\n\n        if output == \"json\":\n            print(out_data)\n        elif output == \"text\":\n            header = list(out_data.keys())\n            header_str = \" | \".join(header)\n            print(header_str)\n\n            if attachment:\n                values_str = \"\\n\".join(out_data[\"name\"])\n            else:\n                values = [str(out_data[key]) for key in header]\n                values_str = \" | \".join(values)\n\n            print(values_str)\n        elif output == \"csv\":\n            header = list(out_data.keys())\n            header_str = \",\".join(header)\n            print(header_str)\n\n            if attachment:\n                values_str = \"\\n\".join(out_data[\"name\"])\n            else:\n                values = [str(out_data[key]) for key in header]\n                values_str = \",\".join(values)\n            print(values_str)\n        else:\n            sys.stderr.write(\"Output Format Not Supported\\n\")\n            return\n\n    except rsexceptions.ReadStoreError as e:\n        sys.stderr.write(f\"ReadStore Error: {e.message}\\n\")\n        return\n</code></pre>"},{"location":"reference/readstore/#readstore_cli.readstore.import_fastq","title":"<code>import_fastq(fastq_template_csv)</code>","text":"<p>Upload fastq files from template</p> <p>Upload fastq files defined in template csv file Template csv file must have columns: FASTQFileName, ReadType, UploadPath</p> <p>Parameters:</p> Name Type Description Default <code>fastq_template_csv</code> <code>str</code> <p>Path to fastq template csv</p> required <p>Raises:</p> Type Description <code>ReadStoreError</code> <p>If file is not found or not a csv file</p> <code>ReadStoreError</code> <p>If upload path is not found</p> <code>ReadStoreError</code> <p>If invalid FASTQ extension</p> <code>ReadStoreError</code> <p>If invalid Read Type</p> Source code in <code>readstore_cli/readstore.py</code> <pre><code>def import_fastq(fastq_template_csv: str):\n    \"\"\"Upload fastq files from template\n\n    Upload fastq files defined in template csv file\n    Template csv file must have columns:\n    FASTQFileName, ReadType, UploadPath\n\n    Args:\n        fastq_template_csv (str): Path to fastq template csv\n\n    Raises:\n        rsexceptions.ReadStoreError: If file is not found or not a csv file\n        rsecxeptions.ReadStoreError: If upload path is not found\n        rsexceptions.ReadStoreError: If invalid FASTQ extension\n        rsexceptions.ReadStoreError: If invalid Read Type\n    \"\"\"\n\n    # Get ReadStore Client and Validate Connection\n    try:\n        client = _get_readstore_client()\n    except rsexceptions.ReadStoreError as e:\n        sys.stderr.write(f\"ReadStore Error: {e.message}\\n\")\n        return\n\n    if not fastq_template_csv.endswith(\".csv\"):\n        sys.stderr.write(\"ReadStore Error: File is not a .csv file\\n\")\n        return\n\n    if not os.path.isfile(fastq_template_csv):\n        sys.stderr.write(f\"ReadStore Error: File Not Found: {fastq_template_csv}\\n\")\n        return\n\n    fq_file_names = []\n    read_types = []\n    upload_paths = []\n\n    with open(fastq_template_csv, \"r\") as f:\n        header = False\n        for line in f.readlines():\n            line = line.rstrip(\"\\n\").split(\",\")\n            if not header:\n                header = line\n                if not all(\n                    e in [\"FASTQFileName\", \"ReadType\", \"UploadPath\"] for e in header\n                ):\n                    sys.stderr.write(\n                        \"\"\"ReadStore Error: Invalid Template Header.\n                        Must be FASTQFileName,ReadType,UploadPath\\n\"\"\"\n                    )\n                else:\n                    header = True\n            else:\n                fq_file_name, read_type, upload_path = line\n\n                if not _validate_read_path(upload_path):\n                    sys.stderr.write(\n                        f\"\\nReadStore Upload: File Not Found: {upload_path}\\n\"\n                    )\n\n                if not upload_path.endswith(tuple(DEFAULT_FASTQ_EXTENSIONS)):\n                    sys.stderr.write(\n                        f\"\\nReadStore Upload: Invalid FASTQ Extension: {upload_path}\\n\"\n                    )\n\n                if read_type not in [\"R1\", \"R2\", \"I1\", \"I2\"]:\n                    sys.stderr.write(\n                        f\"ReadStore Error: Invalid Read Type for file: {upload_path}\\n\"\n                    )\n\n                if fq_file_name == \"\":\n                    sys.stderr.write(\n                        f\"ReadStore Error: Invalid Read Type for file: {upload_path}\\n\"\n                    )\n\n                fq_file_names.append(fq_file_name)\n                read_types.append(read_type)\n                upload_paths.append(upload_path)\n\n    for upload_path, fq_file_name, read_type in zip(\n        upload_paths, fq_file_names, read_types\n    ):\n        print(f\"ReadStore Upload: Start {fq_file_name}\")\n        try:\n            client.upload_fastq(upload_path, fq_file_name, read_type)\n        except rsexceptions.ReadStoreError as e:\n            sys.stderr.write(f\"ReadStore Error: {e.message}\\n\")\n</code></pre>"},{"location":"reference/readstore/#readstore_cli.readstore.list_fq_datasets","title":"<code>list_fq_datasets(project_name=None, project_id=None, role=None, meta=False, attachment=False, pro_data=False, output=None)</code>","text":"<p>List Fastq Datasets</p> <p>List all Fastq Datasets and Filter by Project Options to show only meta and attachments</p> <p>Parameters:</p> Name Type Description Default <code>project_name</code> <code>str | None</code> <p>Filter by Project Name</p> <code>None</code> <code>project_id</code> <code>int | None</code> <p>Filter by Project Id</p> <code>None</code> <code>role</code> <code>str | None</code> <p>Filter by Owner Role</p> <code>None</code> <code>meta</code> <code>bool</code> <p>Show metadata</p> <code>False</code> <code>attachment</code> <code>bool</code> <p>Show attachments</p> <code>False</code> <code>output</code> <code>str | None</code> <p>Set output format. If none use default from config file</p> <code>None</code> Source code in <code>readstore_cli/readstore.py</code> <pre><code>def list_fq_datasets(\n    project_name: str | None = None,\n    project_id: int | None = None,\n    role: str | None = None,\n    meta: bool = False,\n    attachment: bool = False,\n    pro_data: bool = False,\n    output: str | None = None,\n):\n    \"\"\"List Fastq Datasets\n\n    List all Fastq Datasets and Filter by Project\n    Options to show only meta and attachments\n\n    Args:\n        project_name: Filter by Project Name\n        project_id: Filter by Project Id\n        role: Filter by Owner Role\n        meta: Show metadata\n        attachment: Show attachments\n        output: Set output format. If none use default from config file\n    \"\"\"\n\n    # Get ReadStore Client and Validate Connection\n    try:\n        client = _get_readstore_client()\n\n    except rsexceptions.ReadStoreError as e:\n        sys.stderr.write(f\"ReadStore Error: {e.message}\\n\")\n        return\n\n    if output is None:\n        output = client.get_output_format()\n\n    try:\n        fq_datasets = client.list_fastq_datasets(project_name, project_id, role)\n\n        for fq in fq_datasets:\n            if not meta:\n                fq.pop(\"metadata\", None)\n            if not attachment:\n                fq.pop(\"attachments\", None)\n            if not pro_data:\n                fq.pop(\"pro_data\", None)\n\n        if output == \"json\":\n            print(fq_datasets)\n        elif output == \"text\":\n            if len(fq_datasets) &gt; 0:\n                header = list(fq_datasets[0].keys())\n                header_str = \" | \".join(header)\n                print(header_str)\n\n                for fq in fq_datasets:\n                    values = [str(fq[key]) for key in header]\n                    values_str = \" | \".join(values)\n                    print(values_str)\n        elif output == \"csv\":\n            if len(fq_datasets) &gt; 0:\n                header = list(fq_datasets[0].keys())\n                header_str = \",\".join(header)\n                print(header_str)\n\n                for fq in fq_datasets:\n                    values = [str(fq[key]) for key in header]\n                    values_str = \",\".join(values)\n                    print(values_str)\n        else:\n            sys.stderr.write(\"Output Format Not Supported\\n\")\n            return\n\n    except rsexceptions.ReadStoreError as e:\n        sys.stderr.write(f\"ReadStore Error: {e.message}\\n\")\n        return\n</code></pre>"},{"location":"reference/readstore/#readstore_cli.readstore.list_pro_data","title":"<code>list_pro_data(project_id=None, project_name=None, dataset_id=None, dataset_name=None, name=None, data_type=None, meta=False, archived=False, output=None)</code>","text":"<p>List Processed Data</p> <p>List all Processed Data Filter by Project, Dataset, Data Type, Metadata and Archive</p> <p>Parameters:</p> Name Type Description Default <code>project_name</code> <code>str | None</code> <p>Filter by Project Name</p> <code>None</code> <code>project_id</code> <code>int | None</code> <p>Filter by Project ID</p> <code>None</code> <code>dataset_id</code> <code>int | None</code> <p>Filter by Dataset ID</p> <code>None</code> <code>dataset_name</code> <code>str | None</code> <p>Filter by Dataset Name</p> <code>None</code> <code>data_type</code> <code>str | None</code> <p>Filter by Data Type</p> <code>None</code> <code>meta</code> <code>bool</code> <p>Filter by Metadata</p> <code>False</code> <code>archived</code> <code>bool</code> <p>Include Archived Data</p> <code>False</code> <code>output</code> <code>str | None</code> <p>Set output format. If none use default from config file</p> <code>None</code> Source code in <code>readstore_cli/readstore.py</code> <pre><code>def list_pro_data(\n    project_id: int | None = None,\n    project_name: str | None = None,\n    dataset_id: int | None = None,\n    dataset_name: str | None = None,\n    name: str | None = None,\n    data_type: str | None = None,\n    meta: bool = False,\n    archived: bool = False,\n    output: str | None = None,\n):\n    \"\"\"List Processed Data\n\n    List all Processed Data\n    Filter by Project, Dataset, Data Type, Metadata and Archive\n\n    Args:\n        project_name: Filter by Project Name\n        project_id: Filter by Project ID\n        dataset_id: Filter by Dataset ID\n        dataset_name: Filter by Dataset Name\n        data_type: Filter by Data Type\n        meta: Filter by Metadata\n        archived: Include Archived Data\n        output: Set output format. If none use default from config file\n    \"\"\"\n\n    # Get ReadStore Client and Validate Connection\n    try:\n        client = _get_readstore_client()\n    except rsexceptions.ReadStoreError as e:\n        sys.stderr.write(f\"ReadStore Error: {e.message}\\n\")\n        return\n\n    if output is None:\n        output = client.get_output_format()\n\n    try:\n        pro_data = client.list_pro_data(\n            project_id,\n            project_name,\n            dataset_id,\n            dataset_name,\n            name,\n            data_type,\n            archived,\n        )\n\n        for p in pro_data:\n            if not meta:\n                p.pop(\"metadata\", None)\n\n        if output == \"json\":\n            print(pro_data)\n        elif output == \"text\":\n            if len(pro_data) &gt; 0:\n                header = list(pro_data[0].keys())\n                header_str = \" | \".join(header)\n                print(header_str)\n\n                for p in pro_data:\n                    values = [str(p[key]) for key in header]\n                    values_str = \" | \".join(values)\n                    print(values_str)\n        elif output == \"csv\":\n            if len(pro_data) &gt; 0:\n                header = list(pro_data[0].keys())\n                header_str = \",\".join(header)\n                print(header_str)\n\n                for p in pro_data:\n                    values = [str(p[key]) for key in header]\n                    values_str = \",\".join(values)\n                    print(values_str)\n        else:\n            sys.stderr.write(\"Output Format Not Supported\\n\")\n            return\n\n    except rsexceptions.ReadStoreError as e:\n        sys.stderr.write(f\"ReadStore Error: {e.message}\\n\")\n        return\n</code></pre>"},{"location":"reference/readstore/#readstore_cli.readstore.list_projects","title":"<code>list_projects(role=None, meta=False, attachment=False, output=None)</code>","text":"<p>List Projects</p> <p>List all Fastq Projects. Options to add metadata and attachments</p> <p>Role must be in owner, collaborator, creator</p> <p>Parameters:</p> Name Type Description Default <code>role</code> <code>str | None</code> <p>Filter by Owner Role</p> <code>None</code> <code>meta</code> <code>bool</code> <p>Show metadata</p> <code>False</code> <code>attachment</code> <code>bool</code> <p>Show attachments</p> <code>False</code> <code>output</code> <code>str | None</code> <p>Set output format. If none use default from config file</p> <code>None</code> Source code in <code>readstore_cli/readstore.py</code> <pre><code>def list_projects(\n    role: str | None = None,\n    meta: bool = False,\n    attachment: bool = False,\n    output: str | None = None,\n):\n    \"\"\"List Projects\n\n    List all Fastq Projects.\n    Options to add metadata and attachments\n\n    Role must be in owner, collaborator, creator\n\n    Args:\n        role: Filter by Owner Role\n        meta: Show metadata\n        attachment: Show attachments\n        output: Set output format. If none use default from config file\n    \"\"\"\n\n    # Get ReadStore Client and Validate Connection\n    try:\n        client = _get_readstore_client()\n    except rsexceptions.ReadStoreError as e:\n        sys.stderr.write(f\"ReadStore Error: {e.message}\\n\")\n        return\n\n    if output is None:\n        output = client.get_output_format()\n    try:\n        projects = client.list_projects(role)\n\n        for p in projects:\n            p.pop(\"dataset_metadata_keys\", None)\n            if not meta:\n                p.pop(\"metadata\", None)\n            if not attachment:\n                p.pop(\"attachments\", None)\n\n        if output == \"json\":\n            print(projects)\n        elif output == \"text\":\n            if len(projects) &gt; 0:\n                header = list(projects[0].keys())\n                header_str = \" | \".join(header)\n                print(header_str)\n\n                for p in projects:\n                    values = [str(p[key]) for key in header]\n                    values_str = \" | \".join(values)\n                    print(values_str)\n        elif output == \"csv\":\n            if len(projects) &gt; 0:\n                header = list(projects[0].keys())\n                header_str = \",\".join(header)\n                print(header_str)\n\n                for p in projects:\n                    values = [str(p[key]) for key in header]\n                    values_str = \",\".join(values)\n                    print(values_str)\n        else:\n            sys.stderr.write(\"Output Format Not Supported\\n\")\n            return\n\n    except rsexceptions.ReadStoreError as e:\n        sys.stderr.write(f\"ReadStore Error: {e.message}\\n\")\n        return\n</code></pre>"},{"location":"reference/readstore/#readstore_cli.readstore.main","title":"<code>main()</code>","text":"<p>Main function for ReadStore CLI</p> Source code in <code>readstore_cli/readstore.py</code> <pre><code>def main():\n    \"\"\"\n    Main function for ReadStore CLI\n\n    \"\"\"\n\n    args = parser.parse_args()\n\n    # Keep hierarchy of commands. First check for subparsers.\n    if \"config_list\" in args:\n        configure_list()\n\n    elif \"config_run\" in args:\n        configure()\n\n    elif \"upload_run\" in args:\n        upload(fastq_files=args.fastq_files)\n\n    elif \"list_fq_run\" in args:\n        list_fq_datasets(\n            project_name=args.project_name,\n            project_id=args.project_id,\n            role=args.role,\n            meta=args.meta,\n            attachment=args.attachment,\n            pro_data=args.pro_data,\n            output=args.output,\n        )\n\n    elif \"get_fq_run\" in args:\n        read1 = args.read1\n        read2 = args.read2\n        index1 = args.index1\n        index2 = args.index2\n        read1_path = args.read1_path\n        read2_path = args.read2_path\n        index1_path = args.index1_path\n        index2_path = args.index2_path\n\n        meta = args.meta\n        attachment = args.attachment\n        pro_data = args.pro_data\n\n        if (\n            sum([read1,\n                 read2,\n                 index1,\n                 index2,\n                 read1_path,\n                 read2_path,\n                 index1_path,\n                 index2_path,\n                 meta,\n                 attachment,\n                 pro_data]) &gt; 1\n        ):\n            sys.stderr.write(\n                \"\"\"ReadStore Error: Only One Flag Allowed for -r1, -r2,\n                             -i1, -i2, -m, -r1p, -r2p, -i1p, -i2p, -m, -a, -pd\\n\\n\"\"\"\n            )\n            get_fq_parser.print_help()\n        else:\n            get_fastq_dataset(\n                dataset_id=args.id,\n                dataset_name=args.name,\n                meta=meta,\n                attachment=attachment,\n                pro_data=pro_data,\n                read1=read1,\n                read2=read2,\n                index1=index1,\n                index2=index2,\n                read1_path=read1_path,\n                read2_path=read2_path,\n                index1_path=index1_path,\n                index2_path=index2_path,\n                output=args.output,\n            )\n\n    elif \"create_fq_run\" in args:\n\n        if args.project_id:\n            project_ids = [args.project_id]\n        else:\n            project_ids = []\n\n        if args.project_name:\n            project_names = [args.project_name]\n        else:\n            project_names = []\n\n        create_fq_dataset(\n            name=args.name,\n            description=args.description,\n            project_ids=project_ids,\n            project_names=project_names,\n            metadata=args.meta,\n        )\n\n    elif \"update_fq_run\" in args:\n\n        if args.project_id:\n            project_ids = [args.project_id]\n        else:\n            project_ids = None\n\n        if args.project_name:\n            project_names = [args.project_name]\n        else:\n            project_names = None\n\n        update_fq_dataset(\n            dataset_id=args.id,\n            dataset_name=args.name,\n            description=args.description,\n            project_ids=project_ids,\n            project_names=project_names,\n            metadata=args.meta,\n        )\n\n    elif \"download_run\" in args:\n        download_fq_dataset_attachment(\n            attachment_name=args.attachment,\n            outpath=args.outpath,\n            dataset_id=args.id,\n            dataset_name=args.name,\n        )\n\n    elif \"dataset_run\" in args:\n        dataset_parser.print_help()\n\n    elif \"list_project_run\" in args:\n        list_projects(\n            role=args.role,\n            meta=args.meta,\n            attachment=args.attachment,\n            output=args.output,\n        )\n\n    elif \"get_project_run\" in args:\n        get_project(\n            project_id=args.id,\n            project_name=args.name,\n            meta=args.meta,\n            attachment=args.attachment,\n            output=args.output,\n        )\n\n    elif \"create_project_run\" in args:\n        create_project(name=args.name, description=args.description, metadata=args.meta)\n\n    elif \"update_project_run\" in args:\n        update_project(\n            project_id=args.id,\n            project_name=args.name,\n            description=args.description,\n            metadata=args.meta,\n        )\n\n    elif \"download_project_run\" in args:\n        download_project_attachment(\n            attachment_name=args.attachment,\n            outpath=args.outpath,\n            project_id=args.id,\n            project_name=args.name,\n        )\n\n    elif \"project_run\" in args:\n        project_parser.print_help()\n\n    elif \"import_fastq_run\" in args:\n        import_fastq(args.fastq_template[0])\n\n    elif \"import_run\" in args:\n        import_parser.print_help()\n\n    elif \"pro_data_upload_run\" in args:\n\n        dataset_id = args.dataset_id\n        dataset_name = args.dataset_name\n\n        if (not dataset_id) and (not dataset_name):\n            sys.stderr.write(\n                \"ReadStore Error: Must Provide Dataset ID (--did) or Dataset Name (--d) to attach ProData to\\n\"\n            )\n            pro_data_parser.print_help()\n        else:       \n            upload_pro_data(\n                name=args.name,\n                pro_data_file=args.pro_data_file,\n                data_type=args.type,\n                description=args.description,\n                metadata=args.meta,\n                dataset_id=args.dataset_id,\n                dataset_name=args.dataset_name,\n            )\n\n    elif \"pro_data_list_run\" in args:\n        list_pro_data(\n            project_id=args.project_id,\n            project_name=args.project_name,\n            dataset_id=args.dataset_id,\n            dataset_name=args.dataset_name,\n            name=args.name,\n            data_type=args.type,\n            meta=args.meta,\n            archived=args.archived,\n            output=args.output,\n        )\n\n    elif \"pro_data_get_run\" in args:\n        get_pro_data(\n            pro_data_id=args.id,\n            name=args.name,\n            meta=args.meta,\n            upload_path=args.upload_path,\n            version=args.version,\n            dataset_id=args.dataset_id,\n            dataset_name=args.dataset_name,\n            output=args.output,\n        )\n\n    elif \"pro_data_delete_run\" in args:\n        delete_pro_data(\n            pro_data_id=args.id,\n            name=args.name,\n            version=args.version,\n            dataset_id=args.dataset_id,\n            dataset_name=args.dataset_name,\n        )\n\n    elif \"pro_data_run\" in args:\n        pro_data_parser.print_help()\n\n    elif args.version:\n        print(f\"ReadStore CLI Version: {__version__}\")\n        sys.exit(0)\n\n    else:\n        parser.print_help()\n</code></pre>"},{"location":"reference/readstore/#readstore_cli.readstore.upload","title":"<code>upload(fastq_files)</code>","text":"<p>Upload fastq files</p> <p>Upload provided files</p> <p>Check files by extension</p> <p>Parameters:</p> Name Type Description Default <code>fastq_files</code> <code>List[str]</code> <p>Fastq files to upload</p> required Source code in <code>readstore_cli/readstore.py</code> <pre><code>def upload(fastq_files: List[str]):\n    \"\"\"Upload fastq files\n\n    Upload provided files\n\n    Check files by extension\n\n    Args:\n        fastq_files: Fastq files to upload\n    \"\"\"\n\n    # Get ReadStore Client and Validate Connection\n    try:\n        client = _get_readstore_client()\n    except rsexceptions.ReadStoreError as e:\n        sys.stderr.write(f\"ReadStore Error: {e.message}\\n\")\n        return\n\n    for fq in fastq_files:\n        print(f\"ReadStore Upload: Start {fq}\")\n\n        if not os.path.isfile(fq):\n            sys.stderr.write(f\"\\nReadStore Upload: File Not Found: {fq}\\n\")\n            continue\n        elif not fq.endswith(tuple(DEFAULT_FASTQ_EXTENSIONS)):\n            sys.stderr.write(f\"\\nReadStore Upload: Invalid FASTQ Extension: {fq}\\n\")\n        else:\n            try:\n                client.upload_fastq(fq)\n            except rsexceptions.ReadStoreError as e:\n                sys.stderr.write(f\"ReadStore Error: {e.message}\\n\")\n</code></pre>"},{"location":"reference/readstore/#readstore_cli.readstore.upload_pro_data","title":"<code>upload_pro_data(name, pro_data_file, data_type, description, metadata, dataset_id=None, dataset_name=None)</code>","text":"<p>Upload Processed Data</p> Source code in <code>readstore_cli/readstore.py</code> <pre><code>def upload_pro_data(\n    name: str,\n    pro_data_file: str,\n    data_type: str,\n    description: str,\n    metadata: str,\n    dataset_id: int | None = None,\n    dataset_name: str | None = None,\n):\n    \"\"\"Upload Processed Data\"\"\"\n\n    # Get ReadStore Client and Validate Connection\n    try:\n        client = _get_readstore_client()\n    except rsexceptions.ReadStoreError as e:\n        sys.stderr.write(f\"ReadStore Error: {e.message}\\n\")\n        return\n\n    fq_dataset = client.get_fastq_dataset(dataset_id, dataset_name)\n    if fq_dataset == {}:\n        sys.stderr.write(\"ReadStore Error: Dataset to attach ProData Not Found\\n\")\n        return\n\n    fq_dataset_id = fq_dataset[\"id\"]\n\n    # Convert metadata json string to dict\n    try:\n        metadata = json.loads(metadata)\n    except json.JSONDecodeError:\n        sys.stderr.write(\"ReadStore Error: Invalid Metadata JSON String\\n\")\n        return\n\n    print(f\"ReadStore ProData Upload: Start {pro_data_file}\")\n\n    try:\n        client.upload_pro_data(\n            name,\n            pro_data_file,\n            data_type,\n            dataset_id=fq_dataset_id,\n            metadata=metadata,\n            description=description,\n        )\n\n    except rsexceptions.ReadStoreError as e:\n        sys.stderr.write(f\"ReadStore Error: {e.message}\\n\")\n</code></pre>"},{"location":"reference/readstore/#rsclient-module","title":"rsclient module","text":"<p>Provides client for interacting with ReadStore API.</p> <p>Classes:</p> Name Description <code>- RSClient</code> <p>Provides client for interacting with ReadStore API.</p>"},{"location":"reference/readstore/#readstore_cli.rsclient.RSClient","title":"<code>RSClient</code>","text":"<p>A client for interacting with the ReadStore API</p> <p>Attributes:</p> Name Type Description <code>username</code> <p>ReadStore username</p> <code>token</code> <p>ReadStore user token</p> <code>endpoint</code> <p>The endpoint URL for the ReadStore API</p> <code>output_format</code> <p>The default output format for the client</p> <p>Methods:</p> Name Description <code>_test_server_connection</code> <p>Validate server URL</p> <code>_auth_user_token</code> <p>Validate user and token</p> <code>validate_charset</code> <p>Validate charset for query string</p> <code>validate_metadata</code> <p>Validate metadata dict</p> <code>get_output_format</code> <p>Get Output Format set for client</p> <code>upload_fastq</code> <p>Upload Fastq Files</p> <code>get_fq_file</code> <p>Get Fastq File</p> <code>list_fq_files</code> <p>List Fastq Files</p> <code>create_fq_file</code> <p>Create Fastq File</p> <code>update_fq_file</code> <p>Update Fastq File</p> <code>delete_fq_file</code> <p>Delete Fastq File</p> <code>get_fq_file_upload_path</code> <p>Get FASTQ file upload  path</p> <code>list_fastq_datasets</code> <p>List FASTQ Datasets</p> <code>get_fastq_dataset</code> <p>Get FASTQ dataset</p> <code>create_fastq_dataset</code> <p>Create Fastq Dataset</p> <code>update_fastq_dataset</code> <p>Update Fastq Dataset</p> <code>delete_fastq_dataset</code> <p>Delete Fastq Dataset</p> <code>list_projects</code> <p>List Projects</p> <code>get_project</code> <p>Get Project by id or name</p> <code>create_project</code> <p>Create Project</p> <code>update_project</code> <p>Update Project</p> <code>delete_project</code> <p>Delete Project</p> <code>download_project_attachment</code> <p>Download Project Attachments</p> <code>download_fq_dataset_attachment</code> <p>Download Fastq Attach</p> <code>upload_pro_data</code> <p>Upload Processed Data</p> <code>list_pro_data</code> <p>List Processed Data</p> <code>get_pro_data</code> <p>Get Processed Data</p> <code>delete_pro_data</code> <p>Delete Processed Data</p> Source code in <code>readstore_cli/rsclient.py</code> <pre><code>class RSClient:\n    \"\"\"\n        A client for interacting with the ReadStore API\n\n        Attributes:\n            username: ReadStore username\n            token: ReadStore user token\n            endpoint: The endpoint URL for the ReadStore API\n            output_format: The default output format for the client\n\n        Methods:\n            _test_server_connection: Validate server URL\n            _auth_user_token: Validate user and token\n            validate_charset: Validate charset for query string\n            validate_metadata: Validate metadata dict\n            get_output_format: Get Output Format set for client\n            upload_fastq: Upload Fastq Files\n            get_fq_file: Get Fastq File\n            list_fq_files: List Fastq Files\n            create_fq_file: Create Fastq File\n            update_fq_file: Update Fastq File\n            delete_fq_file: Delete Fastq File\n            get_fq_file_upload_path: Get FASTQ file upload  path\n            list_fastq_datasets: List FASTQ Datasets\n            get_fastq_dataset: Get FASTQ dataset\n            create_fastq_dataset: Create Fastq Dataset\n            update_fastq_dataset: Update Fastq Dataset\n            delete_fastq_dataset: Delete Fastq Dataset\n            list_projects: List Projects\n            get_project: Get Project by id or name\n            create_project: Create Project\n            update_project: Update Project\n            delete_project: Delete Project\n            download_project_attachment: Download Project Attachments\n            download_fq_dataset_attachment: Download Fastq Attach\n            upload_pro_data: Upload Processed Data\n            list_pro_data: List Processed Data\n            get_pro_data: Get Processed Data\n            delete_pro_data: Delete Processed Data\n    \"\"\"\n\n    REST_API_VERSION = \"api_x_v1/\"\n    USER_AUTH_TOKEN_ENDPOINT = \"auth_token/\"\n    FASTQ_UPLOAD_ENDPOINT = \"fq_file_upload/\"\n    FQ_DATASET_ENDPOINT = \"fq_dataset/\"\n    FQ_FILE_ENDPOINT = \"fq_file/\"\n    FQ_ATTACHMENT_ENDPOINT = \"fq_attachment/\"\n    PROJECT_ENDPOINT = \"project/\"\n    PROJECT_ATTACHMENT_ENDPOINT = \"project_attachment/\"\n    PRO_DATA_ENDPOINT = \"pro_data/\"\n\n    def __init__(\n        self, username: str, token: str, endpoint_url: str, output_format: str\n    ):\n        \"\"\"Constructor\n\n        Initialize a new RSClient object\n\n        Args:\n            username: ReadStore username\n            token: ReadStore user token\n            endpoint_url: The endpoint URL for the ReadStore API\n            output_format: The default output format for the client\n\n        Raises:\n            rsexceptions.ReadStoreError:\n                Server Connection to API Failed\n            rsexceptions.ReadStoreError:\n                User Authentication Failed\n        \"\"\"\n\n        self.username = username\n        self.token = token\n        self.endpoint = f\"{endpoint_url}/{self.REST_API_VERSION}\"\n        self.output_format = output_format\n        self.auth = HTTPBasicAuth(username, token)\n\n        if not self._test_server_connection():\n            raise rsexceptions.ReadStoreError(\n                f\"Server Connection Failed\\nEndpoint URL: {self.endpoint}\"\n            )\n\n        if not self._auth_user_token():\n            raise rsexceptions.ReadStoreError(\n                f\"User Authentication Failed\\nUsername: {self.username}\"\n            )\n\n    def _test_server_connection(self) -&gt; bool:\n        \"\"\"\n        Validate server URL\n\n        Returns:\n            True if server can be reached else False\n        \"\"\"\n\n        parsed_url = urlparse(self.endpoint)\n\n        if parsed_url.scheme not in [\"http\", \"https\"]:\n            return False\n        else:\n            try:\n                response = requests.head(self.endpoint)\n\n                if response.status_code == 200:\n                    return True\n                else:\n                    return False\n            except requests.exceptions.ConnectionError:\n                return False\n\n    def _auth_user_token(self) -&gt; bool:\n        \"\"\"\n        Validate user and token\n\n        Returns:\n            True if user token is valid else False\n        \"\"\"\n\n        try:\n            auth_endpoint = os.path.join(self.endpoint, self.USER_AUTH_TOKEN_ENDPOINT)\n\n            res = requests.post(auth_endpoint, auth=self.auth)\n\n            if res.status_code != 200:\n                return False\n            else:\n                return True\n\n        except requests.exceptions.ConnectionError:\n            return False\n\n\n    def validate_charset(self, query_str: str) -&gt; bool:\n        \"\"\"\n        Validate charset for query string\n\n        Args:\n            query_str (str): Query string to validate\n\n        Returns:\n            bool: \n        \"\"\"\n\n        allowed = string.digits + string.ascii_lowercase + string.ascii_uppercase + '_-.@'\n        allowed = set(allowed)\n\n        return set(query_str) &lt;= allowed\n\n\n    def get_output_format(self) -&gt; str:\n        \"\"\"\n        Get Output Format set for client\n\n        Return:\n            str output format\n        \"\"\"\n\n        return self.output_format\n\n\n    def upload_fastq(self,\n                     fastq_path: str,\n                     fastq_name: str | None = None,\n                     read_type: str | None = None) -&gt; None:\n        \"\"\"Upload Fastq Files\n\n        Upload Fastq files to ReadStore.\n        Check if file exists and has read permissions.\n\n        fastq_name: List of Fastq names for files to upload\n        read_type: List of read types for files to upload\n\n        Args:\n            fastq_path: List of Fastq files to upload\n            fastq_name: List of Fastq names for files to upload\n            read_types: List of read types for files to upload\n            read_types: Must be in ['R1', 'R2', 'I1', 'I2']\n\n        Raises:\n            rsexceptions.ReadStoreError: If file not found\n            rsexceptions.ReadStoreError: If no read permissions\n            rsexceptions.ReadStoreError: If upload URL request failed\n        \"\"\"\n\n        fq_upload_endpoint = os.path.join(self.endpoint, self.FASTQ_UPLOAD_ENDPOINT)\n\n        # Run parallel uploads of fastq files\n        fastq_path = os.path.abspath(fastq_path)\n\n        # Make sure file exists and\n        if not os.path.exists(fastq_path):\n            raise rsexceptions.ReadStoreError(f\"File Not Found: {fastq_path}\")\n        elif not os.access(fastq_path, os.R_OK):\n            raise rsexceptions.ReadStoreError(f\"No read permissions: {fastq_path}\")\n\n        payload = {\n            \"fq_file_path\": fastq_path,\n        }\n\n        if not fastq_name is None:\n            if fastq_name == \"\":\n                raise rsexceptions.ReadStoreError(\"Fastq Name Is Empty\")\n            if not self.validate_charset(fastq_name):\n                raise rsexceptions.ReadStoreError(\"Invalid Fastq Name\")\n            payload[\"fq_file_name\"] = fastq_name\n\n        if not read_type is None:\n            if read_type not in [\"R1\", \"R2\", \"I1\", \"I2\"]:\n                raise rsexceptions.ReadStoreError(\"Invalid Read Type\")\n            payload[\"read_type\"] = read_type\n\n        res = requests.post(fq_upload_endpoint, json=payload, auth=self.auth)\n\n        if res.status_code not in [200, 204]:\n            res_message = res.json().get(\"detail\", \"No Message\")\n            raise rsexceptions.ReadStoreError(\n                f\"Upload URL Request Failed: {res_message}\"\n            )\n\n\n    def get_fq_file(self, fq_file_id: int) -&gt; Dict:\n        \"\"\"Get Fastq File\n\n        Return Fastq file data by fq_file ID\n\n        Args:\n            fq_file_id: ID (pk) of fq_file\n\n        Returns:\n            dict with fq file data\n        \"\"\"\n\n        fq_file_endpoint = os.path.join(self.endpoint, self.FQ_FILE_ENDPOINT)\n\n\n        res = requests.get(fq_file_endpoint + f'{fq_file_id}/',auth=self.auth)\n\n        if res.status_code not in [200, 204]:\n            try:\n                detail = res.json()\n            except:\n                detail = \"No Message\"\n\n            raise rsexceptions.ReadStoreError(f\"get_fq_file failed: {detail}\")\n        else:\n            return res.json()[0]\n\n\n    def list_fq_files(self) -&gt; List[Dict]:\n        \"\"\"List Fastq Files\n\n        List Fastq files in ReadStore\n\n        Returns:\n            List of Fastq files\n        \"\"\"\n\n        fq_file_endpoint = os.path.join(self.endpoint, self.FQ_FILE_ENDPOINT)\n\n        res = requests.get(fq_file_endpoint, auth=self.auth)\n\n        if res.status_code not in [200, 204]:\n            try:\n                detail = res.json()\n            except:\n                detail = \"No Message\"\n\n            raise rsexceptions.ReadStoreError(f\"list_fq_files failed: {detail}\")\n        else:\n            return res.json()\n\n\n    def create_fq_file(self,\n                       name: str,\n                       read_type: str,\n                       qc_passed: bool,\n                       read_length: int,\n                       num_reads: int,\n                       size_mb: int,\n                       qc_phred_mean: float,\n                       qc_phred: dict,\n                       upload_path: str,\n                       md5_checksum: str,\n                       staging: bool,\n                       pipeline_version: str) -&gt; dict:\n\n        \"\"\"Create Fastq File\n\n        Create Fastq file in ReadStore\n\n        Args:\n            name: Fastq file name\n            read_type: Read type (R1, R2, I1, I2)\n            qc_passed: QC Pass\n            read_length: Read length\n            num_reads: Number of reads\n            size_mb: Size in MB\n            qc_phred_mean: QC Phred Mean\n            qc_phred: QC Phred\n            upload_path: Upload Path\n            md5_checksum: MD5 Checksum\n            staging: Staging\n            pipeline_version: Pipeline Version\n\n        Returns:    \n            dict: Fastq file data\n\n        Raises:\n            rsexceptions.ReadStoreError: If request failed\n        \"\"\"\n\n        fq_file_endpoint = os.path.join(self.endpoint, self.FQ_FILE_ENDPOINT)\n\n        # Define json for post request\n        json = {\n            \"name\": name,\n            \"read_type\": read_type,\n            \"qc_passed\": qc_passed,\n            \"read_length\": read_length,\n            \"num_reads\": num_reads,\n            \"size_mb\": size_mb,\n            \"qc_phred_mean\": qc_phred_mean,\n            \"qc_phred\": qc_phred,\n            \"upload_path\": upload_path,\n            \"md5_checksum\": md5_checksum,\n            \"staging\": staging,\n            \"pipeline_version\": pipeline_version\n        }\n\n        res = requests.post(fq_file_endpoint, json=json, auth=self.auth)\n\n        if res.status_code != 201:\n            try:\n                detail = res.json()\n            except:\n                detail = \"No Message\"\n\n            raise rsexceptions.ReadStoreError(f\"create_fq_file failed: {detail}\")\n        else:\n            return res.json()\n\n\n    def update_fq_file(self,\n                       fq_file_id: int,\n                       name: str,\n                       read_type: str,\n                       qc_passed: bool,\n                       read_length: int,\n                       num_reads: int,\n                       size_mb: int,\n                       qc_phred_mean: float,\n                       qc_phred: dict,\n                       upload_path: str,\n                       md5_checksum: str,\n                       staging: bool,\n                       pipeline_version: str) -&gt; dict:\n\n        \"\"\"Update Fastq File\n\n        Update Fastq file in ReadStore\n\n        Args:\n            fq_file_id: ID of Fastq file\n            name: Fastq file name\n            read_type: Read type (R1, R2, I1, I2)\n            qc_passed: QC Pass\n            read_length: Read length\n            num_reads: Number of reads\n            size_mb: Size in MB\n            qc_phred_mean: QC Phred Mean\n            qc_phred: QC Phred\n            upload_path: Upload Path\n            md5_checksum: MD5 Checksum\n            staging: Staging\n            pipeline_version: Pipeline Version\n\n        Returns:    \n            dict: Fastq file data\n\n        Raises:\n            rsexceptions.ReadStoreError: If request failed\n        \"\"\"\n\n        fq_file_endpoint = os.path.join(self.endpoint, self.FQ_FILE_ENDPOINT, f'{fq_file_id}/')\n\n        # Define json for post request\n        json = {\n            \"name\": name,\n            \"read_type\": read_type,\n            \"qc_passed\": qc_passed,\n            \"read_length\": read_length,\n            \"num_reads\": num_reads,\n            \"size_mb\": size_mb,\n            \"qc_phred_mean\": qc_phred_mean,\n            \"qc_phred\": qc_phred,\n            \"upload_path\": upload_path,\n            \"md5_checksum\": md5_checksum,\n            \"staging\": staging,\n            \"pipeline_version\": pipeline_version\n        }\n\n        res = requests.put(fq_file_endpoint, json=json, auth=self.auth)\n\n        if res.status_code != 200:\n            try:\n                detail = res.json()\n            except:\n                detail = \"No Message\"\n\n            raise rsexceptions.ReadStoreError(f\"update_fq_file failed: {detail}\")\n        else:\n            return res.json()\n\n\n    def delete_fq_file(self, fq_file_id: int):\n        \"\"\"Delete Fastq File\n\n        Delete Fastq file in ReadStore\n\n        Args:\n            fq_file_id: ID of Fastq file\n\n        Raises:\n            rsexceptions.ReadStoreError: If request failed\n        \"\"\"\n\n        fq_file_endpoint = os.path.join(self.endpoint, self.FQ_FILE_ENDPOINT, f'{fq_file_id}/')\n\n        res = requests.delete(fq_file_endpoint, auth=self.auth)\n\n        if not res.status_code in [200, 204]:\n            try:\n                detail = res.json()\n            except:\n                detail = \"No Message\"\n\n            raise rsexceptions.ReadStoreError(f\"delete_fq_file failed: {detail}\")        \n\n\n    def get_fq_file_upload_path(self, fq_file_id: int) -&gt; str:\n        \"\"\"Get FASTQ file upload path\n\n        Get upload path for FASTQ file by fq_file ID\n\n        Args:\n            fq_file_id: ID (pk) of FASTQ file\n\n        Raises:\n            rsexceptions.ReadStoreError: If upload_path is not found\n\n        Returns:\n            str: Upload path\n        \"\"\"\n\n        fq_file = self.get_fq_file(fq_file_id)\n\n        if \"upload_path\" not in fq_file:\n            raise rsexceptions.ReadStoreError(\"upload_path Not Found in FqFile entry\")\n\n        upload_path = fq_file.get(\"upload_path\")\n\n        return upload_path\n\n    def list_fastq_datasets(\n        self,\n        project_name: str | None = None,\n        project_id: int | None = None,\n        role: str | None = None,\n    ) -&gt; List[dict]:\n        \"\"\"\n        List FASTQ Datasets\n\n        List FASTQ datasets and filter by project_name, project_id or role.\n        Role can be owner, collaborator or creator.\n\n        Args:\n            project_name: Filter fq_datasets by project name\n            project_id: Filter fq_datasets by project ID\n            role: Filter fq_datasets by owner role (owner, collaborator, creator)\n\n        Raises:\n            rsexceptions.ReadStoreError if role is not valid\n            rsexceptions.ReadStoreError request failed\n\n        Returns:\n            List[Dict]: FASTQ datasets in JSON format\n        \"\"\"\n\n        fq_dataset_endpoint = os.path.join(self.endpoint, self.FQ_DATASET_ENDPOINT)\n\n        # Define json for post request\n        json = {}\n\n        if role:\n            if role.lower() in [\"owner\", \"collaborator\", \"creator\"]:\n                json[\"role\"] = role\n            else:\n                raise rsexceptions.ReadStoreError(\"Invalid Role\")\n\n        if project_name:\n            json[\"project_name\"] = project_name\n        if project_id:\n            json[\"project_id\"] = project_id\n\n        res = requests.get(fq_dataset_endpoint, params=json, auth=self.auth)\n\n        if res.status_code not in [200, 204]:\n            raise rsexceptions.ReadStoreError(\"list_fastq_datasets Failed\")\n        else:\n            return res.json()\n\n    def get_fastq_dataset(\n        self,\n        dataset_id: int | None = None,\n        dataset_name: str | None = None\n    ) -&gt; Dict:\n        \"\"\"Get FASTQ dataset\n\n        Get FASTQ dataset by provided dataset_id or dataset_name\n        If dataset_name is not unique an error is printed\n\n        Args:\n            dataset_id: fq_dataset ID (or pk) to select\n            dataset_name: fq_dataset Name to select\n\n        Raises:\n            rsexceptions.ReadStoreError: If backend request failed\n            rsexceptions.ReadStoreError:\n                If multiple datasets found with same name.\n                This can occur if datasets with identical name were shared with you.\n\n        Returns:\n            Dict: Json Detail response\n        \"\"\"\n\n        fq_dataset_endpoint = os.path.join(self.endpoint, self.FQ_DATASET_ENDPOINT)\n\n        if dataset_id is None and dataset_name is None: \n            raise rsexceptions.ReadStoreError(\"Dataset ID or Name Required\")\n\n        # Define json for post request\n        json = {}\n        if dataset_id:\n            json[\"id\"] = dataset_id\n        if dataset_name:\n            json[\"name\"] = dataset_name\n\n        res = requests.get(fq_dataset_endpoint, params=json, auth=self.auth)\n\n        # Remove entries not requested\n        if res.status_code not in [200, 204]:\n            raise rsexceptions.ReadStoreError(\"get_fastq_dataset Failed\")\n        else:\n            # If no dataset found, return empty dict\n            if len(res.json()) == 0:\n                return {}\n            # If several datasets found, return error\n            elif len(res.json()) &gt; 1:\n                raise rsexceptions.ReadStoreError(\n                    \"\"\"Multiple Datasets Found.\\n\n                    This can happen if datasets with identical name were\n                    shared with you.\\nUse dataset_id to get the correct dataset.\"\"\"\n                )\n            else:\n                return res.json()[0]\n\n    def create_fastq_dataset(self,\n                            name: str,\n                            description: str,\n                            qc_passed: bool,\n                            paired_end: bool,\n                            index_read: bool,\n                            project_ids: List[int],\n                            project_names: List[str],\n                            metadata: dict,\n                            fq_file_r1_id: int | None,\n                            fq_file_r2_id: int | None,\n                            fq_file_i1_id: int | None,\n                            fq_file_i2_id: int | None) -&gt; dict:\n\n        \"\"\"Create Fastq Dataset \n\n        Create Fastq dataset in ReadStore\n\n        Args:\n            name: Dataset name\n            description: Dataset description\n            qc_passed: QC Pass\n            paired_end: Paired End\n            index_read: Index Read\n            project_ids: List of project IDs\n            project_names: List of project names\n            metadata: Metadata\n            fq_file_r1_id: Fastq file R1 ID\n            fq_file_r2_id: Fastq file R2 ID\n            fq_file_i1_id: Fastq file I1 ID\n            fq_file_i2_id: Fastq file I2 ID\n\n        Returns:\n            dict: Created Fastq dataset\n\n        Raises:\n            rsexceptions.ReadStoreError: If request failed\n        \"\"\"\n\n        fq_dataset_endpoint = os.path.join(self.endpoint, self.FQ_DATASET_ENDPOINT)\n\n        # Define json for post request\n        json = {\n            \"name\": name,\n            \"description\": description,\n            \"qc_passed\": qc_passed,\n            \"paired_end\": paired_end,\n            \"index_read\": index_read,\n            \"project_ids\": project_ids,\n            \"project_names\": project_names,\n            \"metadata\": metadata,\n            \"fq_file_r1\": fq_file_r1_id,\n            \"fq_file_r2\": fq_file_r2_id,\n            \"fq_file_i1\": fq_file_i1_id,\n            \"fq_file_i2\": fq_file_i2_id\n        }\n\n        res = requests.post(fq_dataset_endpoint, json=json, auth=self.auth)\n\n        if res.status_code != 201:\n            try:\n                detail = res.json()\n            except:\n                detail = \"No Message\"\n\n            raise rsexceptions.ReadStoreError(f\"create_fastq_dataset failed: {detail}\")\n        else:\n            return res.json()\n\n    def update_fastq_dataset(self,\n                             dataset_id: int,\n                             name: str,\n                             description: str,\n                             qc_passed: bool,\n                             paired_end: bool,\n                             index_read: bool,\n                             project_ids: List[int],\n                             project_names: List[str],\n                             metadata: dict,\n                             fq_file_r1_id: int | None,\n                             fq_file_r2_id: int | None,\n                             fq_file_i1_id: int | None,\n                             fq_file_i2_id: int | None) -&gt; dict:\n        \"\"\"Update Fastq Dataset\n\n        Update Fastq dataset in ReadStore\n\n        Args:\n            dataset_id: ID of the dataset to update\n            name: Dataset name\n            description: Dataset description\n            qc_passed: QC Pass\n            paired_end: Paired End\n            index_read: Index Read\n            project_ids: List of project IDs\n            project_names: List of project names\n            metadata: Metadata\n            fq_file_r1_id: Fastq file R1 ID\n            fq_file_r2_id: Fastq file R2 ID\n            fq_file_i1_id: Fastq file I1 ID\n            fq_file_i2_id: Fastq file I2 ID\n\n        Returns:\n            dict: Updated Fastq dataset\n\n        Raises:\n            rsexceptions.ReadStoreError: If request failed\n        \"\"\"\n\n        fq_dataset_endpoint = os.path.join(self.endpoint, self.FQ_DATASET_ENDPOINT, f'{dataset_id}/')\n\n        # Define json for put request\n        json = {\n            \"name\": name,\n            \"description\": description,\n            \"qc_passed\": qc_passed,\n            \"paired_end\": paired_end,\n            \"index_read\": index_read,\n            \"project_ids\": project_ids,\n            \"project_names\": project_names,\n            \"metadata\": metadata,\n            \"fq_file_r1\": fq_file_r1_id,\n            \"fq_file_r2\": fq_file_r2_id,\n            \"fq_file_i1\": fq_file_i1_id,\n            \"fq_file_i2\": fq_file_i2_id\n        }\n\n        res = requests.put(fq_dataset_endpoint, json=json, auth=self.auth)\n\n        if res.status_code != 200:\n            try:\n                detail = res.json()\n            except:\n                detail = \"No Message\"\n\n            raise rsexceptions.ReadStoreError(f\"update_fastq_dataset failed: {detail}\")\n        else:\n            return res.json()\n\n    def delete_fastq_dataset(self, dataset_id: int):\n        \"\"\"Delete Fastq Dataset\n\n        Delete Fastq dataset in ReadStore\n\n        Args:\n            dataset_id: ID of Fastq dataset\n\n        Raises:\n            rsexceptions.ReadStoreError: If request failed\n        \"\"\"\n\n        fq_dataset_endpoint = os.path.join(self.endpoint, self.FQ_DATASET_ENDPOINT, f'{dataset_id}/')\n\n        res = requests.delete(fq_dataset_endpoint, auth=self.auth)\n\n        if not res.status_code in [200,204]:\n            try:\n                detail = res.json()\n            except:\n                detail = \"No Message\"\n\n            raise rsexceptions.ReadStoreError(f\"delete_fastq_dataset failed: {detail}\")\n\n\n    def list_projects(self, role: str | None = None) -&gt; List[Dict]:\n        \"\"\"List Projects\n\n        List projects and optionally filter by role\n\n        Args:\n            role: Owner role to filter (owner, collaborator, creator)\n\n        Raises:\n            rsexceptions.ReadStoreError: If role is not valid\n            rsexceptions.ReadStoreError: If request failed\n\n        Returns:\n            List[Dict]: List of projects\n        \"\"\"\n\n        project_endpoint = os.path.join(self.endpoint, self.PROJECT_ENDPOINT)\n\n        # Define json for post request\n        json = {}\n        if role:\n            if role.lower() in [\"owner\", \"collaborator\", \"creator\"]:\n                json[\"role\"] = role\n            else:\n                raise rsexceptions.ReadStoreError(\"Invalid Role\")\n\n        res = requests.get(project_endpoint, params=json, auth=self.auth)\n\n        if res.status_code not in [200, 204]:\n            raise rsexceptions.ReadStoreError(\"list_projects Failed\")\n        else:\n            return res.json()\n\n\n    def get_project(\n        self,\n        project_id: int | None = None,\n        project_name: str | None = None\n    ) -&gt; Dict:\n        \"\"\"Get Individual Project\n\n        Return project details by project_id or project_name\n        If name is duplicated, print error message\n\n        Args:\n            project_id: Project ID\n            project_name: Project Name\n\n        Raise\n            rsexceptions.ReadStoreError: If request failed\n            rsexceptions.ReadStoreError: If duplicate names are found\n\n        Returns:\n            project detail response\n        \"\"\"\n\n        assert project_id or project_name, \"project_id or project_name Required\"\n\n        project_endpoint = os.path.join(self.endpoint, self.PROJECT_ENDPOINT)\n\n        # Define json for post request\n        json = {\"username\": self.username, \"token\": self.token}\n\n        if project_id:\n            json[\"id\"] = project_id\n        if project_name:\n            json[\"name\"] = project_name\n\n        res = requests.get(project_endpoint, params=json, auth=self.auth)\n\n        if res.status_code not in [200, 204]:\n            raise rsexceptions.ReadStoreError(\"get_project Failed\")\n        else:\n            if len(res.json()) == 0:\n                return {}\n            # If several datasets found, return error\n            elif len(res.json()) &gt; 1:\n                raise rsexceptions.ReadStoreError(\n                    \"\"\"Multiple Projects Found.\\n\n                This can happen if Projects with identical name were shared with you.\\n\n                Use unique Project ID to access the correct dataset.\"\"\"\n                )\n            else:\n                return res.json()[0]\n\n    def create_project(self,\n                       name: str,\n                       description: str,\n                       metadata: dict,\n                       dataset_metadata_keys: List[str]) -&gt; dict:\n        \"\"\"Create Project\n\n        Create a new project in ReadStore\n\n        Args:\n            name: Project name\n            description: Project description\n            metadata: Project metadata\n            dataset_metadata_keys: Dataset metadata keys\n\n        Returns:\n            dict: Created project data\n\n        Raises:\n            rsexceptions.ReadStoreError: If request failed\n        \"\"\"\n        project_endpoint = os.path.join(self.endpoint, self.PROJECT_ENDPOINT)\n\n        dataset_metadata_keys = {key: \"\" for key in dataset_metadata_keys}\n\n        json = {\n            \"name\": name,\n            \"description\": description,\n            \"metadata\": metadata,\n            \"dataset_metadata_keys\": dataset_metadata_keys\n        }\n\n        res = requests.post(project_endpoint, json=json, auth=self.auth)\n\n        if res.status_code != 201:\n            try:\n                detail = res.json()\n            except: \n                detail = \"No Message\"\n\n            raise rsexceptions.ReadStoreError(f\"create_project failed: {detail}\")\n        else:\n            return res.json()\n\n\n    def update_project(self,\n                       project_id: int,\n                       name: str,\n                       description: str,\n                       metadata: dict,\n                       dataset_metadata_keys: List[str]) -&gt; dict:        \n        \"\"\"Update Project\n\n        Update an existing project in ReadStore\n\n        Args:\n            project_id: ID of the project to update\n            name: Project name\n            description: Project description\n            metadata: Project metadata\n            dataset_metadata_keys: Dataset metadata keys\n\n        Returns:\n            dict: Updated project data\n\n        Raises:\n            rsexceptions.ReadStoreError: If request failed\n        \"\"\"\n        project_endpoint = os.path.join(self.endpoint, self.PROJECT_ENDPOINT, f'{project_id}/')\n\n        dataset_metadata_keys = {key: \"\" for key in dataset_metadata_keys}\n\n        json = {\n            \"name\": name,\n            \"description\": description,\n            \"metadata\": metadata,\n            \"dataset_metadata_keys\": dataset_metadata_keys\n        }\n\n        res = requests.put(project_endpoint, json=json, auth=self.auth)\n\n        if res.status_code != 200:\n            try:\n                detail = res.json()\n            except:\n                detail = \"No Message\"\n\n            raise rsexceptions.ReadStoreError(f\"update_project failed: {detail}\")\n        else:\n            return res.json()\n\n\n    def delete_project(self, project_id: int):\n        \"\"\"Delete Project\n\n        Delete a project in ReadStore\n\n        Args:\n            project_id: ID of the project to delete\n\n        Raises:\n            rsexceptions.ReadStoreError: If request failed\n        \"\"\"\n\n        project_endpoint = os.path.join(self.endpoint, self.PROJECT_ENDPOINT, f'{project_id}/')\n\n        res = requests.delete(project_endpoint, auth=self.auth)\n\n        if not res.status_code in [200,204]:\n            try:\n                detail = res.json()\n            except:\n                detail = \"No Message\"\n\n            raise rsexceptions.ReadStoreError(f\"delete_project failed: {detail}\")\n\n\n    def download_project_attachment(\n        self,\n        attachment_name: str,\n        outpath: str,\n        project_id: int | None = None,\n        project_name: str | None = None,\n    ):\n        \"\"\"Download Project Attachments\n\n        Download Project Attachment Files to local path\n\n        Args:\n            attachment_name: Attachment name\n            outpath: Path to write to\n            project_id: Id of project\n            project_name: Project name.\n\n        Raises:\n            rsexceptions.ReadStoreError: Request failed\n            rsexceptions.ReadStoreError: Attachment not Found\n            rsexceptions.ReadStoreError: Multiple Attachments Found for Project.\n        \"\"\"\n\n        project_attachment_endpoint = os.path.join(\n            self.endpoint, self.PROJECT_ATTACHMENT_ENDPOINT\n        )\n\n        assert project_id or project_name, \\\n            \"Either project_id or project_name required\"\n\n        # Define json for post request\n        json = {\n            \"attachment_name\": attachment_name\n        }\n\n        if project_id:\n            json[\"project_id\"] = project_id\n        if project_name:\n            json[\"project_name\"] = project_name\n\n        res = requests.get(project_attachment_endpoint, params=json, auth=self.auth)\n\n        if res.status_code not in [200, 204]:\n            raise rsexceptions.ReadStoreError(\"download_project_attachment failed\")\n        elif len(res.json()) == 0:\n            raise rsexceptions.ReadStoreError(\"Attachment Not Found\")\n        elif len(res.json()) &gt; 1:\n            raise rsexceptions.ReadStoreError(\n                \"\"\"Multiple Attachments Found For Project.\n                This can happen if Projects with identical name were shared with you.\\n\n                Use unique Project ID to access the correct attachment.\"\"\"\n            )\n        else:\n            attachment = res.json()[0]\n            with open(outpath, \"wb\") as fh:\n                fh.write(base64.b64decode(attachment[\"body\"]))\n\n\n    def download_fq_dataset_attachment(\n        self,\n        attachment_name: str,\n        outpath: str,\n        dataset_id: int | None = None,\n        dataset_name: str | None = None,\n    ):\n        \"\"\"Fastq Attachments\n\n        Download Fastq Attachments\n\n        Args:\n            attachment_name: Attachment name\n            outpath: Path to write to\n            dataset_id: Id of project\n            dataset_name: Project name.\n\n        Raises:\n            rsexceptions.ReadStoreError: Request failed\n            rsexceptions.ReadStoreError: Attachment not Found\n            rsexceptions.ReadStoreError: Multiple Attachments Found for Project.\n        \"\"\"\n\n        fq_dataset_endpoint = os.path.join(self.endpoint, self.FQ_ATTACHMENT_ENDPOINT)\n\n        assert dataset_id or dataset_name, \"dataset_id or dataset_name required\"\n\n        # Define json for post request\n        json = {\n            \"attachment_name\": attachment_name,\n        }\n\n        if dataset_id:\n            json[\"dataset_id\"] = dataset_id\n        if dataset_name:\n            json[\"dataset_name\"] = dataset_name\n\n        res = requests.get(fq_dataset_endpoint, params=json, auth=self.auth)\n\n        if res.status_code not in [200, 204]:\n            raise rsexceptions.ReadStoreError(\"download_fq_dataset_attachment failed\")\n        elif len(res.json()) == 0:\n            raise rsexceptions.ReadStoreError(\"Attachment Not Found\")\n        elif len(res.json()) &gt; 1:\n            raise rsexceptions.ReadStoreError(\n                \"\"\"Multiple Attachments Found For Dataset.\n                This can happen if Datasets with identical name were shared with you.\\n\n                Use unique Dataset ID to access the correct attachment.\"\"\"\n            )\n        else:\n            attachment = res.json()[0]\n            with open(outpath, \"wb\") as fh:\n                fh.write(base64.b64decode(attachment[\"body\"]))\n\n    def upload_pro_data(self,\n                        name: str,\n                        pro_data_path: str,\n                        data_type: str,\n                        dataset_id: int | None = None,\n                        dataset_name: str | None = None,\n                        metadata: dict = {},\n                        description: str = \"\") -&gt; None:\n        \"\"\"Upload Processed Data\n\n        Upload Pro Data to ReadStore\n\n        Args:\n            pro_data: Pro Data in JSON format\n\n        Raises:\n            rsexceptions.ReadStoreError: If upload request failed\n        \"\"\"\n\n        pro_data_endpoint = os.path.join(self.endpoint, self.PRO_DATA_ENDPOINT)\n\n        # Run parallel uploads of fastq files\n        pro_data_path = os.path.abspath(pro_data_path)\n\n        # Make sure file exists and\n        if not os.path.exists(pro_data_path):\n            raise rsexceptions.ReadStoreError(f\"File Not Found: {pro_data_path}\")\n        elif not os.access(pro_data_path, os.R_OK):\n            raise rsexceptions.ReadStoreError(f\"No read permissions: {pro_data_path}\")\n\n        # Define json for post request\n        json = {\n            \"name\" : name,\n            \"data_type\": data_type,\n            \"upload_path\": pro_data_path,\n            \"metadata\": metadata,\n            \"description\" : description,\n        }\n\n        if dataset_id:\n            json['dataset_id'] = dataset_id\n        if dataset_name:\n            json['dataset_name'] = dataset_name        \n\n        res = requests.post(pro_data_endpoint, json=json, auth=self.auth)\n\n        if res.status_code == 403:\n            raise rsexceptions.ReadStoreError(f\"Upload ProData Failed: {res.json().get('detail')}\")\n        elif res.status_code not in [201, 204]:\n            raise rsexceptions.ReadStoreError(\"upload_pro_data failed\")\n\n\n    def list_pro_data(self,\n                      project_id: int | None = None,\n                      project_name: str | None = None,\n                      dataset_id: int | None = None,\n                      dataset_name: str | None = None,\n                      name: str | None = None,\n                      data_type: str | None = None,\n                      include_archived: bool = False) -&gt; List[Dict]:\n        \"\"\"List Processed Data\n\n        List Pro Data for Dataset\n\n        Args:\n            dataset_id: Dataset ID\n\n        Raises:\n            rsexceptions.ReadStoreError: If request failed\n\n        Returns:\n            List[Dict]: List of Pro Data\n        \"\"\"\n\n        pro_data_endpoint = os.path.join(self.endpoint, self.PRO_DATA_ENDPOINT)\n\n        # Define json for post request\n        json = {\n            'project_id': project_id,\n            'project_name': project_name,\n            'dataset_id': dataset_id,\n            'dataset_name': dataset_name,\n            'name': name,\n            'data_type': data_type\n        }\n\n        if not include_archived:\n            json['valid'] = True\n\n        res = requests.get(pro_data_endpoint, params=json, auth=self.auth)\n\n        if res.status_code not in [200, 204]:\n            raise rsexceptions.ReadStoreError(\"list_pro_data failed\")\n        else:\n            return res.json()\n\n\n    def get_pro_data(self,\n                    pro_data_id: int | None = None,\n                    name: str | None = None,\n                    version: int | None = None,\n                    dataset_id: int | None = None,\n                    dataset_name: str | None = None) -&gt; List[Dict]:   \n\n        \"\"\"List Processed Data\n\n        List Pro Data for Dataset\n\n        Args:\n            dataset_id: Dataset ID\n\n        Raises:\n            rsexceptions.ReadStoreError: If request failed\n\n        Returns:\n            List[Dict]: List of Pro Data\n        \"\"\"\n\n        if not pro_data_id:\n            assert name and (dataset_id or dataset_name), \"name and dataset_id or dataset_name required\"\n\n        pro_data_endpoint = os.path.join(self.endpoint, self.PRO_DATA_ENDPOINT)\n\n        if not version:\n            valid = 'true'\n        else:\n            valid = 'false'\n\n\n        # Define json for post request\n        json = {\n            'dataset_id': dataset_id,\n            'dataset_name': dataset_name,\n            'name': name,\n            'version': version,\n            'valid': valid,\n            'detail': 'true'\n        }\n\n        if pro_data_id:\n            res = requests.get(pro_data_endpoint + f'{pro_data_id}/', auth=self.auth)\n        else:\n            res = requests.get(pro_data_endpoint, params=json, auth=self.auth)\n\n        if res.status_code not in [200, 204]:\n            raise rsexceptions.ReadStoreError(\"list_pro_data failed\")\n        else:\n            if len(res.json()) == 0:\n                return {}\n            # If several datasets found, return error\n            elif len(res.json()) &gt; 1:\n                raise rsexceptions.ReadStoreError(\n                    \"\"\"Multiple Projects Found.\\n\n                This can happen if Projects with identical name were shared with you.\\n\n                Use unique Project ID to access the correct dataset.\"\"\"\n                )\n            else:\n                return res.json()[0]\n\n    def delete_pro_data(self,\n                        pro_data_id: int | None = None,\n                        name: str | None = None,\n                        dataset_id: int | None = None,\n                        dataset_name: str | None = None,\n                        version: int | None = None) -&gt; List[Dict]:   \n\n        \"\"\"Delete Processed Data\n\n        Delete Pro Data for Dataset\n\n        Args:\n            dataset_id: Dataset ID\n\n        Raises:\n            rsexceptions.ReadStoreError: If request failed\n\n        Returns:\n            List[Dict]: List of Pro Data\n        \"\"\"\n\n        if not pro_data_id:\n            assert name and (dataset_id or dataset_name), \"name and dataset_id or dataset_name required\"\n\n        pro_data_endpoint = os.path.join(self.endpoint, self.PRO_DATA_ENDPOINT)\n\n        # Define json for post request\n        json = {\n            'dataset_id': dataset_id,\n            'dataset_name': dataset_name,\n            'name': name,\n            'version': version,\n        }\n\n        if pro_data_id:\n            res = requests.delete(pro_data_endpoint + f'{pro_data_id}/', auth=self.auth)\n        else:\n            res = requests.delete(pro_data_endpoint, params=json, auth=self.auth)\n\n        if res.status_code == 400:\n            detail = res.json().get('detail', 'No Message')\n            if detail == 'ProData not found':\n                raise rsexceptions.ReadStoreError(\"ProData not found\")\n            else:\n                raise rsexceptions.ReadStoreError(\"delete_pro_data failed\")\n        elif res.status_code == 403:\n            raise rsexceptions.ReadStoreError(f\"ProData Delete Failed: {res.json().get('detail')}\")\n        elif res.status_code in [200, 204]:\n            return res.json().get('id')\n        else:\n            raise rsexceptions.ReadStoreError(\"delete_pro_data failed\")\n</code></pre>"},{"location":"reference/readstore/#readstore_cli.rsclient.RSClient.__init__","title":"<code>__init__(username, token, endpoint_url, output_format)</code>","text":"<p>Constructor</p> <p>Initialize a new RSClient object</p> <p>Parameters:</p> Name Type Description Default <code>username</code> <code>str</code> <p>ReadStore username</p> required <code>token</code> <code>str</code> <p>ReadStore user token</p> required <code>endpoint_url</code> <code>str</code> <p>The endpoint URL for the ReadStore API</p> required <code>output_format</code> <code>str</code> <p>The default output format for the client</p> required <p>Raises:</p> Type Description <code>ReadStoreError</code> <p>Server Connection to API Failed</p> <code>ReadStoreError</code> <p>User Authentication Failed</p> Source code in <code>readstore_cli/rsclient.py</code> <pre><code>def __init__(\n    self, username: str, token: str, endpoint_url: str, output_format: str\n):\n    \"\"\"Constructor\n\n    Initialize a new RSClient object\n\n    Args:\n        username: ReadStore username\n        token: ReadStore user token\n        endpoint_url: The endpoint URL for the ReadStore API\n        output_format: The default output format for the client\n\n    Raises:\n        rsexceptions.ReadStoreError:\n            Server Connection to API Failed\n        rsexceptions.ReadStoreError:\n            User Authentication Failed\n    \"\"\"\n\n    self.username = username\n    self.token = token\n    self.endpoint = f\"{endpoint_url}/{self.REST_API_VERSION}\"\n    self.output_format = output_format\n    self.auth = HTTPBasicAuth(username, token)\n\n    if not self._test_server_connection():\n        raise rsexceptions.ReadStoreError(\n            f\"Server Connection Failed\\nEndpoint URL: {self.endpoint}\"\n        )\n\n    if not self._auth_user_token():\n        raise rsexceptions.ReadStoreError(\n            f\"User Authentication Failed\\nUsername: {self.username}\"\n        )\n</code></pre>"},{"location":"reference/readstore/#readstore_cli.rsclient.RSClient._auth_user_token","title":"<code>_auth_user_token()</code>","text":"<p>Validate user and token</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if user token is valid else False</p> Source code in <code>readstore_cli/rsclient.py</code> <pre><code>def _auth_user_token(self) -&gt; bool:\n    \"\"\"\n    Validate user and token\n\n    Returns:\n        True if user token is valid else False\n    \"\"\"\n\n    try:\n        auth_endpoint = os.path.join(self.endpoint, self.USER_AUTH_TOKEN_ENDPOINT)\n\n        res = requests.post(auth_endpoint, auth=self.auth)\n\n        if res.status_code != 200:\n            return False\n        else:\n            return True\n\n    except requests.exceptions.ConnectionError:\n        return False\n</code></pre>"},{"location":"reference/readstore/#readstore_cli.rsclient.RSClient._test_server_connection","title":"<code>_test_server_connection()</code>","text":"<p>Validate server URL</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if server can be reached else False</p> Source code in <code>readstore_cli/rsclient.py</code> <pre><code>def _test_server_connection(self) -&gt; bool:\n    \"\"\"\n    Validate server URL\n\n    Returns:\n        True if server can be reached else False\n    \"\"\"\n\n    parsed_url = urlparse(self.endpoint)\n\n    if parsed_url.scheme not in [\"http\", \"https\"]:\n        return False\n    else:\n        try:\n            response = requests.head(self.endpoint)\n\n            if response.status_code == 200:\n                return True\n            else:\n                return False\n        except requests.exceptions.ConnectionError:\n            return False\n</code></pre>"},{"location":"reference/readstore/#readstore_cli.rsclient.RSClient.create_fastq_dataset","title":"<code>create_fastq_dataset(name, description, qc_passed, paired_end, index_read, project_ids, project_names, metadata, fq_file_r1_id, fq_file_r2_id, fq_file_i1_id, fq_file_i2_id)</code>","text":"<p>Create Fastq Dataset </p> <p>Create Fastq dataset in ReadStore</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Dataset name</p> required <code>description</code> <code>str</code> <p>Dataset description</p> required <code>qc_passed</code> <code>bool</code> <p>QC Pass</p> required <code>paired_end</code> <code>bool</code> <p>Paired End</p> required <code>index_read</code> <code>bool</code> <p>Index Read</p> required <code>project_ids</code> <code>List[int]</code> <p>List of project IDs</p> required <code>project_names</code> <code>List[str]</code> <p>List of project names</p> required <code>metadata</code> <code>dict</code> <p>Metadata</p> required <code>fq_file_r1_id</code> <code>int | None</code> <p>Fastq file R1 ID</p> required <code>fq_file_r2_id</code> <code>int | None</code> <p>Fastq file R2 ID</p> required <code>fq_file_i1_id</code> <code>int | None</code> <p>Fastq file I1 ID</p> required <code>fq_file_i2_id</code> <code>int | None</code> <p>Fastq file I2 ID</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>Created Fastq dataset</p> <p>Raises:</p> Type Description <code>ReadStoreError</code> <p>If request failed</p> Source code in <code>readstore_cli/rsclient.py</code> <pre><code>def create_fastq_dataset(self,\n                        name: str,\n                        description: str,\n                        qc_passed: bool,\n                        paired_end: bool,\n                        index_read: bool,\n                        project_ids: List[int],\n                        project_names: List[str],\n                        metadata: dict,\n                        fq_file_r1_id: int | None,\n                        fq_file_r2_id: int | None,\n                        fq_file_i1_id: int | None,\n                        fq_file_i2_id: int | None) -&gt; dict:\n\n    \"\"\"Create Fastq Dataset \n\n    Create Fastq dataset in ReadStore\n\n    Args:\n        name: Dataset name\n        description: Dataset description\n        qc_passed: QC Pass\n        paired_end: Paired End\n        index_read: Index Read\n        project_ids: List of project IDs\n        project_names: List of project names\n        metadata: Metadata\n        fq_file_r1_id: Fastq file R1 ID\n        fq_file_r2_id: Fastq file R2 ID\n        fq_file_i1_id: Fastq file I1 ID\n        fq_file_i2_id: Fastq file I2 ID\n\n    Returns:\n        dict: Created Fastq dataset\n\n    Raises:\n        rsexceptions.ReadStoreError: If request failed\n    \"\"\"\n\n    fq_dataset_endpoint = os.path.join(self.endpoint, self.FQ_DATASET_ENDPOINT)\n\n    # Define json for post request\n    json = {\n        \"name\": name,\n        \"description\": description,\n        \"qc_passed\": qc_passed,\n        \"paired_end\": paired_end,\n        \"index_read\": index_read,\n        \"project_ids\": project_ids,\n        \"project_names\": project_names,\n        \"metadata\": metadata,\n        \"fq_file_r1\": fq_file_r1_id,\n        \"fq_file_r2\": fq_file_r2_id,\n        \"fq_file_i1\": fq_file_i1_id,\n        \"fq_file_i2\": fq_file_i2_id\n    }\n\n    res = requests.post(fq_dataset_endpoint, json=json, auth=self.auth)\n\n    if res.status_code != 201:\n        try:\n            detail = res.json()\n        except:\n            detail = \"No Message\"\n\n        raise rsexceptions.ReadStoreError(f\"create_fastq_dataset failed: {detail}\")\n    else:\n        return res.json()\n</code></pre>"},{"location":"reference/readstore/#readstore_cli.rsclient.RSClient.create_fq_file","title":"<code>create_fq_file(name, read_type, qc_passed, read_length, num_reads, size_mb, qc_phred_mean, qc_phred, upload_path, md5_checksum, staging, pipeline_version)</code>","text":"<p>Create Fastq File</p> <p>Create Fastq file in ReadStore</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Fastq file name</p> required <code>read_type</code> <code>str</code> <p>Read type (R1, R2, I1, I2)</p> required <code>qc_passed</code> <code>bool</code> <p>QC Pass</p> required <code>read_length</code> <code>int</code> <p>Read length</p> required <code>num_reads</code> <code>int</code> <p>Number of reads</p> required <code>size_mb</code> <code>int</code> <p>Size in MB</p> required <code>qc_phred_mean</code> <code>float</code> <p>QC Phred Mean</p> required <code>qc_phred</code> <code>dict</code> <p>QC Phred</p> required <code>upload_path</code> <code>str</code> <p>Upload Path</p> required <code>md5_checksum</code> <code>str</code> <p>MD5 Checksum</p> required <code>staging</code> <code>bool</code> <p>Staging</p> required <code>pipeline_version</code> <code>str</code> <p>Pipeline Version</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>Fastq file data</p> <p>Raises:</p> Type Description <code>ReadStoreError</code> <p>If request failed</p> Source code in <code>readstore_cli/rsclient.py</code> <pre><code>def create_fq_file(self,\n                   name: str,\n                   read_type: str,\n                   qc_passed: bool,\n                   read_length: int,\n                   num_reads: int,\n                   size_mb: int,\n                   qc_phred_mean: float,\n                   qc_phred: dict,\n                   upload_path: str,\n                   md5_checksum: str,\n                   staging: bool,\n                   pipeline_version: str) -&gt; dict:\n\n    \"\"\"Create Fastq File\n\n    Create Fastq file in ReadStore\n\n    Args:\n        name: Fastq file name\n        read_type: Read type (R1, R2, I1, I2)\n        qc_passed: QC Pass\n        read_length: Read length\n        num_reads: Number of reads\n        size_mb: Size in MB\n        qc_phred_mean: QC Phred Mean\n        qc_phred: QC Phred\n        upload_path: Upload Path\n        md5_checksum: MD5 Checksum\n        staging: Staging\n        pipeline_version: Pipeline Version\n\n    Returns:    \n        dict: Fastq file data\n\n    Raises:\n        rsexceptions.ReadStoreError: If request failed\n    \"\"\"\n\n    fq_file_endpoint = os.path.join(self.endpoint, self.FQ_FILE_ENDPOINT)\n\n    # Define json for post request\n    json = {\n        \"name\": name,\n        \"read_type\": read_type,\n        \"qc_passed\": qc_passed,\n        \"read_length\": read_length,\n        \"num_reads\": num_reads,\n        \"size_mb\": size_mb,\n        \"qc_phred_mean\": qc_phred_mean,\n        \"qc_phred\": qc_phred,\n        \"upload_path\": upload_path,\n        \"md5_checksum\": md5_checksum,\n        \"staging\": staging,\n        \"pipeline_version\": pipeline_version\n    }\n\n    res = requests.post(fq_file_endpoint, json=json, auth=self.auth)\n\n    if res.status_code != 201:\n        try:\n            detail = res.json()\n        except:\n            detail = \"No Message\"\n\n        raise rsexceptions.ReadStoreError(f\"create_fq_file failed: {detail}\")\n    else:\n        return res.json()\n</code></pre>"},{"location":"reference/readstore/#readstore_cli.rsclient.RSClient.create_project","title":"<code>create_project(name, description, metadata, dataset_metadata_keys)</code>","text":"<p>Create Project</p> <p>Create a new project in ReadStore</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Project name</p> required <code>description</code> <code>str</code> <p>Project description</p> required <code>metadata</code> <code>dict</code> <p>Project metadata</p> required <code>dataset_metadata_keys</code> <code>List[str]</code> <p>Dataset metadata keys</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>Created project data</p> <p>Raises:</p> Type Description <code>ReadStoreError</code> <p>If request failed</p> Source code in <code>readstore_cli/rsclient.py</code> <pre><code>def create_project(self,\n                   name: str,\n                   description: str,\n                   metadata: dict,\n                   dataset_metadata_keys: List[str]) -&gt; dict:\n    \"\"\"Create Project\n\n    Create a new project in ReadStore\n\n    Args:\n        name: Project name\n        description: Project description\n        metadata: Project metadata\n        dataset_metadata_keys: Dataset metadata keys\n\n    Returns:\n        dict: Created project data\n\n    Raises:\n        rsexceptions.ReadStoreError: If request failed\n    \"\"\"\n    project_endpoint = os.path.join(self.endpoint, self.PROJECT_ENDPOINT)\n\n    dataset_metadata_keys = {key: \"\" for key in dataset_metadata_keys}\n\n    json = {\n        \"name\": name,\n        \"description\": description,\n        \"metadata\": metadata,\n        \"dataset_metadata_keys\": dataset_metadata_keys\n    }\n\n    res = requests.post(project_endpoint, json=json, auth=self.auth)\n\n    if res.status_code != 201:\n        try:\n            detail = res.json()\n        except: \n            detail = \"No Message\"\n\n        raise rsexceptions.ReadStoreError(f\"create_project failed: {detail}\")\n    else:\n        return res.json()\n</code></pre>"},{"location":"reference/readstore/#readstore_cli.rsclient.RSClient.delete_fastq_dataset","title":"<code>delete_fastq_dataset(dataset_id)</code>","text":"<p>Delete Fastq Dataset</p> <p>Delete Fastq dataset in ReadStore</p> <p>Parameters:</p> Name Type Description Default <code>dataset_id</code> <code>int</code> <p>ID of Fastq dataset</p> required <p>Raises:</p> Type Description <code>ReadStoreError</code> <p>If request failed</p> Source code in <code>readstore_cli/rsclient.py</code> <pre><code>def delete_fastq_dataset(self, dataset_id: int):\n    \"\"\"Delete Fastq Dataset\n\n    Delete Fastq dataset in ReadStore\n\n    Args:\n        dataset_id: ID of Fastq dataset\n\n    Raises:\n        rsexceptions.ReadStoreError: If request failed\n    \"\"\"\n\n    fq_dataset_endpoint = os.path.join(self.endpoint, self.FQ_DATASET_ENDPOINT, f'{dataset_id}/')\n\n    res = requests.delete(fq_dataset_endpoint, auth=self.auth)\n\n    if not res.status_code in [200,204]:\n        try:\n            detail = res.json()\n        except:\n            detail = \"No Message\"\n\n        raise rsexceptions.ReadStoreError(f\"delete_fastq_dataset failed: {detail}\")\n</code></pre>"},{"location":"reference/readstore/#readstore_cli.rsclient.RSClient.delete_fq_file","title":"<code>delete_fq_file(fq_file_id)</code>","text":"<p>Delete Fastq File</p> <p>Delete Fastq file in ReadStore</p> <p>Parameters:</p> Name Type Description Default <code>fq_file_id</code> <code>int</code> <p>ID of Fastq file</p> required <p>Raises:</p> Type Description <code>ReadStoreError</code> <p>If request failed</p> Source code in <code>readstore_cli/rsclient.py</code> <pre><code>def delete_fq_file(self, fq_file_id: int):\n    \"\"\"Delete Fastq File\n\n    Delete Fastq file in ReadStore\n\n    Args:\n        fq_file_id: ID of Fastq file\n\n    Raises:\n        rsexceptions.ReadStoreError: If request failed\n    \"\"\"\n\n    fq_file_endpoint = os.path.join(self.endpoint, self.FQ_FILE_ENDPOINT, f'{fq_file_id}/')\n\n    res = requests.delete(fq_file_endpoint, auth=self.auth)\n\n    if not res.status_code in [200, 204]:\n        try:\n            detail = res.json()\n        except:\n            detail = \"No Message\"\n\n        raise rsexceptions.ReadStoreError(f\"delete_fq_file failed: {detail}\")        \n</code></pre>"},{"location":"reference/readstore/#readstore_cli.rsclient.RSClient.delete_pro_data","title":"<code>delete_pro_data(pro_data_id=None, name=None, dataset_id=None, dataset_name=None, version=None)</code>","text":"<p>Delete Processed Data</p> <p>Delete Pro Data for Dataset</p> <p>Parameters:</p> Name Type Description Default <code>dataset_id</code> <code>int | None</code> <p>Dataset ID</p> <code>None</code> <p>Raises:</p> Type Description <code>ReadStoreError</code> <p>If request failed</p> <p>Returns:</p> Type Description <code>List[Dict]</code> <p>List[Dict]: List of Pro Data</p> Source code in <code>readstore_cli/rsclient.py</code> <pre><code>def delete_pro_data(self,\n                    pro_data_id: int | None = None,\n                    name: str | None = None,\n                    dataset_id: int | None = None,\n                    dataset_name: str | None = None,\n                    version: int | None = None) -&gt; List[Dict]:   \n\n    \"\"\"Delete Processed Data\n\n    Delete Pro Data for Dataset\n\n    Args:\n        dataset_id: Dataset ID\n\n    Raises:\n        rsexceptions.ReadStoreError: If request failed\n\n    Returns:\n        List[Dict]: List of Pro Data\n    \"\"\"\n\n    if not pro_data_id:\n        assert name and (dataset_id or dataset_name), \"name and dataset_id or dataset_name required\"\n\n    pro_data_endpoint = os.path.join(self.endpoint, self.PRO_DATA_ENDPOINT)\n\n    # Define json for post request\n    json = {\n        'dataset_id': dataset_id,\n        'dataset_name': dataset_name,\n        'name': name,\n        'version': version,\n    }\n\n    if pro_data_id:\n        res = requests.delete(pro_data_endpoint + f'{pro_data_id}/', auth=self.auth)\n    else:\n        res = requests.delete(pro_data_endpoint, params=json, auth=self.auth)\n\n    if res.status_code == 400:\n        detail = res.json().get('detail', 'No Message')\n        if detail == 'ProData not found':\n            raise rsexceptions.ReadStoreError(\"ProData not found\")\n        else:\n            raise rsexceptions.ReadStoreError(\"delete_pro_data failed\")\n    elif res.status_code == 403:\n        raise rsexceptions.ReadStoreError(f\"ProData Delete Failed: {res.json().get('detail')}\")\n    elif res.status_code in [200, 204]:\n        return res.json().get('id')\n    else:\n        raise rsexceptions.ReadStoreError(\"delete_pro_data failed\")\n</code></pre>"},{"location":"reference/readstore/#readstore_cli.rsclient.RSClient.delete_project","title":"<code>delete_project(project_id)</code>","text":"<p>Delete Project</p> <p>Delete a project in ReadStore</p> <p>Parameters:</p> Name Type Description Default <code>project_id</code> <code>int</code> <p>ID of the project to delete</p> required <p>Raises:</p> Type Description <code>ReadStoreError</code> <p>If request failed</p> Source code in <code>readstore_cli/rsclient.py</code> <pre><code>def delete_project(self, project_id: int):\n    \"\"\"Delete Project\n\n    Delete a project in ReadStore\n\n    Args:\n        project_id: ID of the project to delete\n\n    Raises:\n        rsexceptions.ReadStoreError: If request failed\n    \"\"\"\n\n    project_endpoint = os.path.join(self.endpoint, self.PROJECT_ENDPOINT, f'{project_id}/')\n\n    res = requests.delete(project_endpoint, auth=self.auth)\n\n    if not res.status_code in [200,204]:\n        try:\n            detail = res.json()\n        except:\n            detail = \"No Message\"\n\n        raise rsexceptions.ReadStoreError(f\"delete_project failed: {detail}\")\n</code></pre>"},{"location":"reference/readstore/#readstore_cli.rsclient.RSClient.download_fq_dataset_attachment","title":"<code>download_fq_dataset_attachment(attachment_name, outpath, dataset_id=None, dataset_name=None)</code>","text":"<p>Fastq Attachments</p> <p>Download Fastq Attachments</p> <p>Parameters:</p> Name Type Description Default <code>attachment_name</code> <code>str</code> <p>Attachment name</p> required <code>outpath</code> <code>str</code> <p>Path to write to</p> required <code>dataset_id</code> <code>int | None</code> <p>Id of project</p> <code>None</code> <code>dataset_name</code> <code>str | None</code> <p>Project name.</p> <code>None</code> <p>Raises:</p> Type Description <code>ReadStoreError</code> <p>Request failed</p> <code>ReadStoreError</code> <p>Attachment not Found</p> <code>ReadStoreError</code> <p>Multiple Attachments Found for Project.</p> Source code in <code>readstore_cli/rsclient.py</code> <pre><code>def download_fq_dataset_attachment(\n    self,\n    attachment_name: str,\n    outpath: str,\n    dataset_id: int | None = None,\n    dataset_name: str | None = None,\n):\n    \"\"\"Fastq Attachments\n\n    Download Fastq Attachments\n\n    Args:\n        attachment_name: Attachment name\n        outpath: Path to write to\n        dataset_id: Id of project\n        dataset_name: Project name.\n\n    Raises:\n        rsexceptions.ReadStoreError: Request failed\n        rsexceptions.ReadStoreError: Attachment not Found\n        rsexceptions.ReadStoreError: Multiple Attachments Found for Project.\n    \"\"\"\n\n    fq_dataset_endpoint = os.path.join(self.endpoint, self.FQ_ATTACHMENT_ENDPOINT)\n\n    assert dataset_id or dataset_name, \"dataset_id or dataset_name required\"\n\n    # Define json for post request\n    json = {\n        \"attachment_name\": attachment_name,\n    }\n\n    if dataset_id:\n        json[\"dataset_id\"] = dataset_id\n    if dataset_name:\n        json[\"dataset_name\"] = dataset_name\n\n    res = requests.get(fq_dataset_endpoint, params=json, auth=self.auth)\n\n    if res.status_code not in [200, 204]:\n        raise rsexceptions.ReadStoreError(\"download_fq_dataset_attachment failed\")\n    elif len(res.json()) == 0:\n        raise rsexceptions.ReadStoreError(\"Attachment Not Found\")\n    elif len(res.json()) &gt; 1:\n        raise rsexceptions.ReadStoreError(\n            \"\"\"Multiple Attachments Found For Dataset.\n            This can happen if Datasets with identical name were shared with you.\\n\n            Use unique Dataset ID to access the correct attachment.\"\"\"\n        )\n    else:\n        attachment = res.json()[0]\n        with open(outpath, \"wb\") as fh:\n            fh.write(base64.b64decode(attachment[\"body\"]))\n</code></pre>"},{"location":"reference/readstore/#readstore_cli.rsclient.RSClient.download_project_attachment","title":"<code>download_project_attachment(attachment_name, outpath, project_id=None, project_name=None)</code>","text":"<p>Download Project Attachments</p> <p>Download Project Attachment Files to local path</p> <p>Parameters:</p> Name Type Description Default <code>attachment_name</code> <code>str</code> <p>Attachment name</p> required <code>outpath</code> <code>str</code> <p>Path to write to</p> required <code>project_id</code> <code>int | None</code> <p>Id of project</p> <code>None</code> <code>project_name</code> <code>str | None</code> <p>Project name.</p> <code>None</code> <p>Raises:</p> Type Description <code>ReadStoreError</code> <p>Request failed</p> <code>ReadStoreError</code> <p>Attachment not Found</p> <code>ReadStoreError</code> <p>Multiple Attachments Found for Project.</p> Source code in <code>readstore_cli/rsclient.py</code> <pre><code>def download_project_attachment(\n    self,\n    attachment_name: str,\n    outpath: str,\n    project_id: int | None = None,\n    project_name: str | None = None,\n):\n    \"\"\"Download Project Attachments\n\n    Download Project Attachment Files to local path\n\n    Args:\n        attachment_name: Attachment name\n        outpath: Path to write to\n        project_id: Id of project\n        project_name: Project name.\n\n    Raises:\n        rsexceptions.ReadStoreError: Request failed\n        rsexceptions.ReadStoreError: Attachment not Found\n        rsexceptions.ReadStoreError: Multiple Attachments Found for Project.\n    \"\"\"\n\n    project_attachment_endpoint = os.path.join(\n        self.endpoint, self.PROJECT_ATTACHMENT_ENDPOINT\n    )\n\n    assert project_id or project_name, \\\n        \"Either project_id or project_name required\"\n\n    # Define json for post request\n    json = {\n        \"attachment_name\": attachment_name\n    }\n\n    if project_id:\n        json[\"project_id\"] = project_id\n    if project_name:\n        json[\"project_name\"] = project_name\n\n    res = requests.get(project_attachment_endpoint, params=json, auth=self.auth)\n\n    if res.status_code not in [200, 204]:\n        raise rsexceptions.ReadStoreError(\"download_project_attachment failed\")\n    elif len(res.json()) == 0:\n        raise rsexceptions.ReadStoreError(\"Attachment Not Found\")\n    elif len(res.json()) &gt; 1:\n        raise rsexceptions.ReadStoreError(\n            \"\"\"Multiple Attachments Found For Project.\n            This can happen if Projects with identical name were shared with you.\\n\n            Use unique Project ID to access the correct attachment.\"\"\"\n        )\n    else:\n        attachment = res.json()[0]\n        with open(outpath, \"wb\") as fh:\n            fh.write(base64.b64decode(attachment[\"body\"]))\n</code></pre>"},{"location":"reference/readstore/#readstore_cli.rsclient.RSClient.get_fastq_dataset","title":"<code>get_fastq_dataset(dataset_id=None, dataset_name=None)</code>","text":"<p>Get FASTQ dataset</p> <p>Get FASTQ dataset by provided dataset_id or dataset_name If dataset_name is not unique an error is printed</p> <p>Parameters:</p> Name Type Description Default <code>dataset_id</code> <code>int | None</code> <p>fq_dataset ID (or pk) to select</p> <code>None</code> <code>dataset_name</code> <code>str | None</code> <p>fq_dataset Name to select</p> <code>None</code> <p>Raises:</p> Type Description <code>ReadStoreError</code> <p>If backend request failed</p> <code>ReadStoreError</code> <p>If multiple datasets found with same name. This can occur if datasets with identical name were shared with you.</p> <p>Returns:</p> Name Type Description <code>Dict</code> <code>Dict</code> <p>Json Detail response</p> Source code in <code>readstore_cli/rsclient.py</code> <pre><code>def get_fastq_dataset(\n    self,\n    dataset_id: int | None = None,\n    dataset_name: str | None = None\n) -&gt; Dict:\n    \"\"\"Get FASTQ dataset\n\n    Get FASTQ dataset by provided dataset_id or dataset_name\n    If dataset_name is not unique an error is printed\n\n    Args:\n        dataset_id: fq_dataset ID (or pk) to select\n        dataset_name: fq_dataset Name to select\n\n    Raises:\n        rsexceptions.ReadStoreError: If backend request failed\n        rsexceptions.ReadStoreError:\n            If multiple datasets found with same name.\n            This can occur if datasets with identical name were shared with you.\n\n    Returns:\n        Dict: Json Detail response\n    \"\"\"\n\n    fq_dataset_endpoint = os.path.join(self.endpoint, self.FQ_DATASET_ENDPOINT)\n\n    if dataset_id is None and dataset_name is None: \n        raise rsexceptions.ReadStoreError(\"Dataset ID or Name Required\")\n\n    # Define json for post request\n    json = {}\n    if dataset_id:\n        json[\"id\"] = dataset_id\n    if dataset_name:\n        json[\"name\"] = dataset_name\n\n    res = requests.get(fq_dataset_endpoint, params=json, auth=self.auth)\n\n    # Remove entries not requested\n    if res.status_code not in [200, 204]:\n        raise rsexceptions.ReadStoreError(\"get_fastq_dataset Failed\")\n    else:\n        # If no dataset found, return empty dict\n        if len(res.json()) == 0:\n            return {}\n        # If several datasets found, return error\n        elif len(res.json()) &gt; 1:\n            raise rsexceptions.ReadStoreError(\n                \"\"\"Multiple Datasets Found.\\n\n                This can happen if datasets with identical name were\n                shared with you.\\nUse dataset_id to get the correct dataset.\"\"\"\n            )\n        else:\n            return res.json()[0]\n</code></pre>"},{"location":"reference/readstore/#readstore_cli.rsclient.RSClient.get_fq_file","title":"<code>get_fq_file(fq_file_id)</code>","text":"<p>Get Fastq File</p> <p>Return Fastq file data by fq_file ID</p> <p>Parameters:</p> Name Type Description Default <code>fq_file_id</code> <code>int</code> <p>ID (pk) of fq_file</p> required <p>Returns:</p> Type Description <code>Dict</code> <p>dict with fq file data</p> Source code in <code>readstore_cli/rsclient.py</code> <pre><code>def get_fq_file(self, fq_file_id: int) -&gt; Dict:\n    \"\"\"Get Fastq File\n\n    Return Fastq file data by fq_file ID\n\n    Args:\n        fq_file_id: ID (pk) of fq_file\n\n    Returns:\n        dict with fq file data\n    \"\"\"\n\n    fq_file_endpoint = os.path.join(self.endpoint, self.FQ_FILE_ENDPOINT)\n\n\n    res = requests.get(fq_file_endpoint + f'{fq_file_id}/',auth=self.auth)\n\n    if res.status_code not in [200, 204]:\n        try:\n            detail = res.json()\n        except:\n            detail = \"No Message\"\n\n        raise rsexceptions.ReadStoreError(f\"get_fq_file failed: {detail}\")\n    else:\n        return res.json()[0]\n</code></pre>"},{"location":"reference/readstore/#readstore_cli.rsclient.RSClient.get_fq_file_upload_path","title":"<code>get_fq_file_upload_path(fq_file_id)</code>","text":"<p>Get FASTQ file upload path</p> <p>Get upload path for FASTQ file by fq_file ID</p> <p>Parameters:</p> Name Type Description Default <code>fq_file_id</code> <code>int</code> <p>ID (pk) of FASTQ file</p> required <p>Raises:</p> Type Description <code>ReadStoreError</code> <p>If upload_path is not found</p> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Upload path</p> Source code in <code>readstore_cli/rsclient.py</code> <pre><code>def get_fq_file_upload_path(self, fq_file_id: int) -&gt; str:\n    \"\"\"Get FASTQ file upload path\n\n    Get upload path for FASTQ file by fq_file ID\n\n    Args:\n        fq_file_id: ID (pk) of FASTQ file\n\n    Raises:\n        rsexceptions.ReadStoreError: If upload_path is not found\n\n    Returns:\n        str: Upload path\n    \"\"\"\n\n    fq_file = self.get_fq_file(fq_file_id)\n\n    if \"upload_path\" not in fq_file:\n        raise rsexceptions.ReadStoreError(\"upload_path Not Found in FqFile entry\")\n\n    upload_path = fq_file.get(\"upload_path\")\n\n    return upload_path\n</code></pre>"},{"location":"reference/readstore/#readstore_cli.rsclient.RSClient.get_output_format","title":"<code>get_output_format()</code>","text":"<p>Get Output Format set for client</p> Return <p>str output format</p> Source code in <code>readstore_cli/rsclient.py</code> <pre><code>def get_output_format(self) -&gt; str:\n    \"\"\"\n    Get Output Format set for client\n\n    Return:\n        str output format\n    \"\"\"\n\n    return self.output_format\n</code></pre>"},{"location":"reference/readstore/#readstore_cli.rsclient.RSClient.get_pro_data","title":"<code>get_pro_data(pro_data_id=None, name=None, version=None, dataset_id=None, dataset_name=None)</code>","text":"<p>List Processed Data</p> <p>List Pro Data for Dataset</p> <p>Parameters:</p> Name Type Description Default <code>dataset_id</code> <code>int | None</code> <p>Dataset ID</p> <code>None</code> <p>Raises:</p> Type Description <code>ReadStoreError</code> <p>If request failed</p> <p>Returns:</p> Type Description <code>List[Dict]</code> <p>List[Dict]: List of Pro Data</p> Source code in <code>readstore_cli/rsclient.py</code> <pre><code>def get_pro_data(self,\n                pro_data_id: int | None = None,\n                name: str | None = None,\n                version: int | None = None,\n                dataset_id: int | None = None,\n                dataset_name: str | None = None) -&gt; List[Dict]:   \n\n    \"\"\"List Processed Data\n\n    List Pro Data for Dataset\n\n    Args:\n        dataset_id: Dataset ID\n\n    Raises:\n        rsexceptions.ReadStoreError: If request failed\n\n    Returns:\n        List[Dict]: List of Pro Data\n    \"\"\"\n\n    if not pro_data_id:\n        assert name and (dataset_id or dataset_name), \"name and dataset_id or dataset_name required\"\n\n    pro_data_endpoint = os.path.join(self.endpoint, self.PRO_DATA_ENDPOINT)\n\n    if not version:\n        valid = 'true'\n    else:\n        valid = 'false'\n\n\n    # Define json for post request\n    json = {\n        'dataset_id': dataset_id,\n        'dataset_name': dataset_name,\n        'name': name,\n        'version': version,\n        'valid': valid,\n        'detail': 'true'\n    }\n\n    if pro_data_id:\n        res = requests.get(pro_data_endpoint + f'{pro_data_id}/', auth=self.auth)\n    else:\n        res = requests.get(pro_data_endpoint, params=json, auth=self.auth)\n\n    if res.status_code not in [200, 204]:\n        raise rsexceptions.ReadStoreError(\"list_pro_data failed\")\n    else:\n        if len(res.json()) == 0:\n            return {}\n        # If several datasets found, return error\n        elif len(res.json()) &gt; 1:\n            raise rsexceptions.ReadStoreError(\n                \"\"\"Multiple Projects Found.\\n\n            This can happen if Projects with identical name were shared with you.\\n\n            Use unique Project ID to access the correct dataset.\"\"\"\n            )\n        else:\n            return res.json()[0]\n</code></pre>"},{"location":"reference/readstore/#readstore_cli.rsclient.RSClient.get_project","title":"<code>get_project(project_id=None, project_name=None)</code>","text":"<p>Get Individual Project</p> <p>Return project details by project_id or project_name If name is duplicated, print error message</p> <p>Parameters:</p> Name Type Description Default <code>project_id</code> <code>int | None</code> <p>Project ID</p> <code>None</code> <code>project_name</code> <code>str | None</code> <p>Project Name</p> <code>None</code> <p>Raise     rsexceptions.ReadStoreError: If request failed     rsexceptions.ReadStoreError: If duplicate names are found</p> <p>Returns:</p> Type Description <code>Dict</code> <p>project detail response</p> Source code in <code>readstore_cli/rsclient.py</code> <pre><code>def get_project(\n    self,\n    project_id: int | None = None,\n    project_name: str | None = None\n) -&gt; Dict:\n    \"\"\"Get Individual Project\n\n    Return project details by project_id or project_name\n    If name is duplicated, print error message\n\n    Args:\n        project_id: Project ID\n        project_name: Project Name\n\n    Raise\n        rsexceptions.ReadStoreError: If request failed\n        rsexceptions.ReadStoreError: If duplicate names are found\n\n    Returns:\n        project detail response\n    \"\"\"\n\n    assert project_id or project_name, \"project_id or project_name Required\"\n\n    project_endpoint = os.path.join(self.endpoint, self.PROJECT_ENDPOINT)\n\n    # Define json for post request\n    json = {\"username\": self.username, \"token\": self.token}\n\n    if project_id:\n        json[\"id\"] = project_id\n    if project_name:\n        json[\"name\"] = project_name\n\n    res = requests.get(project_endpoint, params=json, auth=self.auth)\n\n    if res.status_code not in [200, 204]:\n        raise rsexceptions.ReadStoreError(\"get_project Failed\")\n    else:\n        if len(res.json()) == 0:\n            return {}\n        # If several datasets found, return error\n        elif len(res.json()) &gt; 1:\n            raise rsexceptions.ReadStoreError(\n                \"\"\"Multiple Projects Found.\\n\n            This can happen if Projects with identical name were shared with you.\\n\n            Use unique Project ID to access the correct dataset.\"\"\"\n            )\n        else:\n            return res.json()[0]\n</code></pre>"},{"location":"reference/readstore/#readstore_cli.rsclient.RSClient.list_fastq_datasets","title":"<code>list_fastq_datasets(project_name=None, project_id=None, role=None)</code>","text":"<p>List FASTQ Datasets</p> <p>List FASTQ datasets and filter by project_name, project_id or role. Role can be owner, collaborator or creator.</p> <p>Parameters:</p> Name Type Description Default <code>project_name</code> <code>str | None</code> <p>Filter fq_datasets by project name</p> <code>None</code> <code>project_id</code> <code>int | None</code> <p>Filter fq_datasets by project ID</p> <code>None</code> <code>role</code> <code>str | None</code> <p>Filter fq_datasets by owner role (owner, collaborator, creator)</p> <code>None</code> <p>Returns:</p> Type Description <code>List[dict]</code> <p>List[Dict]: FASTQ datasets in JSON format</p> Source code in <code>readstore_cli/rsclient.py</code> <pre><code>def list_fastq_datasets(\n    self,\n    project_name: str | None = None,\n    project_id: int | None = None,\n    role: str | None = None,\n) -&gt; List[dict]:\n    \"\"\"\n    List FASTQ Datasets\n\n    List FASTQ datasets and filter by project_name, project_id or role.\n    Role can be owner, collaborator or creator.\n\n    Args:\n        project_name: Filter fq_datasets by project name\n        project_id: Filter fq_datasets by project ID\n        role: Filter fq_datasets by owner role (owner, collaborator, creator)\n\n    Raises:\n        rsexceptions.ReadStoreError if role is not valid\n        rsexceptions.ReadStoreError request failed\n\n    Returns:\n        List[Dict]: FASTQ datasets in JSON format\n    \"\"\"\n\n    fq_dataset_endpoint = os.path.join(self.endpoint, self.FQ_DATASET_ENDPOINT)\n\n    # Define json for post request\n    json = {}\n\n    if role:\n        if role.lower() in [\"owner\", \"collaborator\", \"creator\"]:\n            json[\"role\"] = role\n        else:\n            raise rsexceptions.ReadStoreError(\"Invalid Role\")\n\n    if project_name:\n        json[\"project_name\"] = project_name\n    if project_id:\n        json[\"project_id\"] = project_id\n\n    res = requests.get(fq_dataset_endpoint, params=json, auth=self.auth)\n\n    if res.status_code not in [200, 204]:\n        raise rsexceptions.ReadStoreError(\"list_fastq_datasets Failed\")\n    else:\n        return res.json()\n</code></pre>"},{"location":"reference/readstore/#readstore_cli.rsclient.RSClient.list_fq_files","title":"<code>list_fq_files()</code>","text":"<p>List Fastq Files</p> <p>List Fastq files in ReadStore</p> <p>Returns:</p> Type Description <code>List[Dict]</code> <p>List of Fastq files</p> Source code in <code>readstore_cli/rsclient.py</code> <pre><code>def list_fq_files(self) -&gt; List[Dict]:\n    \"\"\"List Fastq Files\n\n    List Fastq files in ReadStore\n\n    Returns:\n        List of Fastq files\n    \"\"\"\n\n    fq_file_endpoint = os.path.join(self.endpoint, self.FQ_FILE_ENDPOINT)\n\n    res = requests.get(fq_file_endpoint, auth=self.auth)\n\n    if res.status_code not in [200, 204]:\n        try:\n            detail = res.json()\n        except:\n            detail = \"No Message\"\n\n        raise rsexceptions.ReadStoreError(f\"list_fq_files failed: {detail}\")\n    else:\n        return res.json()\n</code></pre>"},{"location":"reference/readstore/#readstore_cli.rsclient.RSClient.list_pro_data","title":"<code>list_pro_data(project_id=None, project_name=None, dataset_id=None, dataset_name=None, name=None, data_type=None, include_archived=False)</code>","text":"<p>List Processed Data</p> <p>List Pro Data for Dataset</p> <p>Parameters:</p> Name Type Description Default <code>dataset_id</code> <code>int | None</code> <p>Dataset ID</p> <code>None</code> <p>Raises:</p> Type Description <code>ReadStoreError</code> <p>If request failed</p> <p>Returns:</p> Type Description <code>List[Dict]</code> <p>List[Dict]: List of Pro Data</p> Source code in <code>readstore_cli/rsclient.py</code> <pre><code>def list_pro_data(self,\n                  project_id: int | None = None,\n                  project_name: str | None = None,\n                  dataset_id: int | None = None,\n                  dataset_name: str | None = None,\n                  name: str | None = None,\n                  data_type: str | None = None,\n                  include_archived: bool = False) -&gt; List[Dict]:\n    \"\"\"List Processed Data\n\n    List Pro Data for Dataset\n\n    Args:\n        dataset_id: Dataset ID\n\n    Raises:\n        rsexceptions.ReadStoreError: If request failed\n\n    Returns:\n        List[Dict]: List of Pro Data\n    \"\"\"\n\n    pro_data_endpoint = os.path.join(self.endpoint, self.PRO_DATA_ENDPOINT)\n\n    # Define json for post request\n    json = {\n        'project_id': project_id,\n        'project_name': project_name,\n        'dataset_id': dataset_id,\n        'dataset_name': dataset_name,\n        'name': name,\n        'data_type': data_type\n    }\n\n    if not include_archived:\n        json['valid'] = True\n\n    res = requests.get(pro_data_endpoint, params=json, auth=self.auth)\n\n    if res.status_code not in [200, 204]:\n        raise rsexceptions.ReadStoreError(\"list_pro_data failed\")\n    else:\n        return res.json()\n</code></pre>"},{"location":"reference/readstore/#readstore_cli.rsclient.RSClient.list_projects","title":"<code>list_projects(role=None)</code>","text":"<p>List Projects</p> <p>List projects and optionally filter by role</p> <p>Parameters:</p> Name Type Description Default <code>role</code> <code>str | None</code> <p>Owner role to filter (owner, collaborator, creator)</p> <code>None</code> <p>Raises:</p> Type Description <code>ReadStoreError</code> <p>If role is not valid</p> <code>ReadStoreError</code> <p>If request failed</p> <p>Returns:</p> Type Description <code>List[Dict]</code> <p>List[Dict]: List of projects</p> Source code in <code>readstore_cli/rsclient.py</code> <pre><code>def list_projects(self, role: str | None = None) -&gt; List[Dict]:\n    \"\"\"List Projects\n\n    List projects and optionally filter by role\n\n    Args:\n        role: Owner role to filter (owner, collaborator, creator)\n\n    Raises:\n        rsexceptions.ReadStoreError: If role is not valid\n        rsexceptions.ReadStoreError: If request failed\n\n    Returns:\n        List[Dict]: List of projects\n    \"\"\"\n\n    project_endpoint = os.path.join(self.endpoint, self.PROJECT_ENDPOINT)\n\n    # Define json for post request\n    json = {}\n    if role:\n        if role.lower() in [\"owner\", \"collaborator\", \"creator\"]:\n            json[\"role\"] = role\n        else:\n            raise rsexceptions.ReadStoreError(\"Invalid Role\")\n\n    res = requests.get(project_endpoint, params=json, auth=self.auth)\n\n    if res.status_code not in [200, 204]:\n        raise rsexceptions.ReadStoreError(\"list_projects Failed\")\n    else:\n        return res.json()\n</code></pre>"},{"location":"reference/readstore/#readstore_cli.rsclient.RSClient.update_fastq_dataset","title":"<code>update_fastq_dataset(dataset_id, name, description, qc_passed, paired_end, index_read, project_ids, project_names, metadata, fq_file_r1_id, fq_file_r2_id, fq_file_i1_id, fq_file_i2_id)</code>","text":"<p>Update Fastq Dataset</p> <p>Update Fastq dataset in ReadStore</p> <p>Parameters:</p> Name Type Description Default <code>dataset_id</code> <code>int</code> <p>ID of the dataset to update</p> required <code>name</code> <code>str</code> <p>Dataset name</p> required <code>description</code> <code>str</code> <p>Dataset description</p> required <code>qc_passed</code> <code>bool</code> <p>QC Pass</p> required <code>paired_end</code> <code>bool</code> <p>Paired End</p> required <code>index_read</code> <code>bool</code> <p>Index Read</p> required <code>project_ids</code> <code>List[int]</code> <p>List of project IDs</p> required <code>project_names</code> <code>List[str]</code> <p>List of project names</p> required <code>metadata</code> <code>dict</code> <p>Metadata</p> required <code>fq_file_r1_id</code> <code>int | None</code> <p>Fastq file R1 ID</p> required <code>fq_file_r2_id</code> <code>int | None</code> <p>Fastq file R2 ID</p> required <code>fq_file_i1_id</code> <code>int | None</code> <p>Fastq file I1 ID</p> required <code>fq_file_i2_id</code> <code>int | None</code> <p>Fastq file I2 ID</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>Updated Fastq dataset</p> <p>Raises:</p> Type Description <code>ReadStoreError</code> <p>If request failed</p> Source code in <code>readstore_cli/rsclient.py</code> <pre><code>def update_fastq_dataset(self,\n                         dataset_id: int,\n                         name: str,\n                         description: str,\n                         qc_passed: bool,\n                         paired_end: bool,\n                         index_read: bool,\n                         project_ids: List[int],\n                         project_names: List[str],\n                         metadata: dict,\n                         fq_file_r1_id: int | None,\n                         fq_file_r2_id: int | None,\n                         fq_file_i1_id: int | None,\n                         fq_file_i2_id: int | None) -&gt; dict:\n    \"\"\"Update Fastq Dataset\n\n    Update Fastq dataset in ReadStore\n\n    Args:\n        dataset_id: ID of the dataset to update\n        name: Dataset name\n        description: Dataset description\n        qc_passed: QC Pass\n        paired_end: Paired End\n        index_read: Index Read\n        project_ids: List of project IDs\n        project_names: List of project names\n        metadata: Metadata\n        fq_file_r1_id: Fastq file R1 ID\n        fq_file_r2_id: Fastq file R2 ID\n        fq_file_i1_id: Fastq file I1 ID\n        fq_file_i2_id: Fastq file I2 ID\n\n    Returns:\n        dict: Updated Fastq dataset\n\n    Raises:\n        rsexceptions.ReadStoreError: If request failed\n    \"\"\"\n\n    fq_dataset_endpoint = os.path.join(self.endpoint, self.FQ_DATASET_ENDPOINT, f'{dataset_id}/')\n\n    # Define json for put request\n    json = {\n        \"name\": name,\n        \"description\": description,\n        \"qc_passed\": qc_passed,\n        \"paired_end\": paired_end,\n        \"index_read\": index_read,\n        \"project_ids\": project_ids,\n        \"project_names\": project_names,\n        \"metadata\": metadata,\n        \"fq_file_r1\": fq_file_r1_id,\n        \"fq_file_r2\": fq_file_r2_id,\n        \"fq_file_i1\": fq_file_i1_id,\n        \"fq_file_i2\": fq_file_i2_id\n    }\n\n    res = requests.put(fq_dataset_endpoint, json=json, auth=self.auth)\n\n    if res.status_code != 200:\n        try:\n            detail = res.json()\n        except:\n            detail = \"No Message\"\n\n        raise rsexceptions.ReadStoreError(f\"update_fastq_dataset failed: {detail}\")\n    else:\n        return res.json()\n</code></pre>"},{"location":"reference/readstore/#readstore_cli.rsclient.RSClient.update_fq_file","title":"<code>update_fq_file(fq_file_id, name, read_type, qc_passed, read_length, num_reads, size_mb, qc_phred_mean, qc_phred, upload_path, md5_checksum, staging, pipeline_version)</code>","text":"<p>Update Fastq File</p> <p>Update Fastq file in ReadStore</p> <p>Parameters:</p> Name Type Description Default <code>fq_file_id</code> <code>int</code> <p>ID of Fastq file</p> required <code>name</code> <code>str</code> <p>Fastq file name</p> required <code>read_type</code> <code>str</code> <p>Read type (R1, R2, I1, I2)</p> required <code>qc_passed</code> <code>bool</code> <p>QC Pass</p> required <code>read_length</code> <code>int</code> <p>Read length</p> required <code>num_reads</code> <code>int</code> <p>Number of reads</p> required <code>size_mb</code> <code>int</code> <p>Size in MB</p> required <code>qc_phred_mean</code> <code>float</code> <p>QC Phred Mean</p> required <code>qc_phred</code> <code>dict</code> <p>QC Phred</p> required <code>upload_path</code> <code>str</code> <p>Upload Path</p> required <code>md5_checksum</code> <code>str</code> <p>MD5 Checksum</p> required <code>staging</code> <code>bool</code> <p>Staging</p> required <code>pipeline_version</code> <code>str</code> <p>Pipeline Version</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>Fastq file data</p> <p>Raises:</p> Type Description <code>ReadStoreError</code> <p>If request failed</p> Source code in <code>readstore_cli/rsclient.py</code> <pre><code>def update_fq_file(self,\n                   fq_file_id: int,\n                   name: str,\n                   read_type: str,\n                   qc_passed: bool,\n                   read_length: int,\n                   num_reads: int,\n                   size_mb: int,\n                   qc_phred_mean: float,\n                   qc_phred: dict,\n                   upload_path: str,\n                   md5_checksum: str,\n                   staging: bool,\n                   pipeline_version: str) -&gt; dict:\n\n    \"\"\"Update Fastq File\n\n    Update Fastq file in ReadStore\n\n    Args:\n        fq_file_id: ID of Fastq file\n        name: Fastq file name\n        read_type: Read type (R1, R2, I1, I2)\n        qc_passed: QC Pass\n        read_length: Read length\n        num_reads: Number of reads\n        size_mb: Size in MB\n        qc_phred_mean: QC Phred Mean\n        qc_phred: QC Phred\n        upload_path: Upload Path\n        md5_checksum: MD5 Checksum\n        staging: Staging\n        pipeline_version: Pipeline Version\n\n    Returns:    \n        dict: Fastq file data\n\n    Raises:\n        rsexceptions.ReadStoreError: If request failed\n    \"\"\"\n\n    fq_file_endpoint = os.path.join(self.endpoint, self.FQ_FILE_ENDPOINT, f'{fq_file_id}/')\n\n    # Define json for post request\n    json = {\n        \"name\": name,\n        \"read_type\": read_type,\n        \"qc_passed\": qc_passed,\n        \"read_length\": read_length,\n        \"num_reads\": num_reads,\n        \"size_mb\": size_mb,\n        \"qc_phred_mean\": qc_phred_mean,\n        \"qc_phred\": qc_phred,\n        \"upload_path\": upload_path,\n        \"md5_checksum\": md5_checksum,\n        \"staging\": staging,\n        \"pipeline_version\": pipeline_version\n    }\n\n    res = requests.put(fq_file_endpoint, json=json, auth=self.auth)\n\n    if res.status_code != 200:\n        try:\n            detail = res.json()\n        except:\n            detail = \"No Message\"\n\n        raise rsexceptions.ReadStoreError(f\"update_fq_file failed: {detail}\")\n    else:\n        return res.json()\n</code></pre>"},{"location":"reference/readstore/#readstore_cli.rsclient.RSClient.update_project","title":"<code>update_project(project_id, name, description, metadata, dataset_metadata_keys)</code>","text":"<p>Update Project</p> <p>Update an existing project in ReadStore</p> <p>Parameters:</p> Name Type Description Default <code>project_id</code> <code>int</code> <p>ID of the project to update</p> required <code>name</code> <code>str</code> <p>Project name</p> required <code>description</code> <code>str</code> <p>Project description</p> required <code>metadata</code> <code>dict</code> <p>Project metadata</p> required <code>dataset_metadata_keys</code> <code>List[str]</code> <p>Dataset metadata keys</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>Updated project data</p> <p>Raises:</p> Type Description <code>ReadStoreError</code> <p>If request failed</p> Source code in <code>readstore_cli/rsclient.py</code> <pre><code>def update_project(self,\n                   project_id: int,\n                   name: str,\n                   description: str,\n                   metadata: dict,\n                   dataset_metadata_keys: List[str]) -&gt; dict:        \n    \"\"\"Update Project\n\n    Update an existing project in ReadStore\n\n    Args:\n        project_id: ID of the project to update\n        name: Project name\n        description: Project description\n        metadata: Project metadata\n        dataset_metadata_keys: Dataset metadata keys\n\n    Returns:\n        dict: Updated project data\n\n    Raises:\n        rsexceptions.ReadStoreError: If request failed\n    \"\"\"\n    project_endpoint = os.path.join(self.endpoint, self.PROJECT_ENDPOINT, f'{project_id}/')\n\n    dataset_metadata_keys = {key: \"\" for key in dataset_metadata_keys}\n\n    json = {\n        \"name\": name,\n        \"description\": description,\n        \"metadata\": metadata,\n        \"dataset_metadata_keys\": dataset_metadata_keys\n    }\n\n    res = requests.put(project_endpoint, json=json, auth=self.auth)\n\n    if res.status_code != 200:\n        try:\n            detail = res.json()\n        except:\n            detail = \"No Message\"\n\n        raise rsexceptions.ReadStoreError(f\"update_project failed: {detail}\")\n    else:\n        return res.json()\n</code></pre>"},{"location":"reference/readstore/#readstore_cli.rsclient.RSClient.upload_fastq","title":"<code>upload_fastq(fastq_path, fastq_name=None, read_type=None)</code>","text":"<p>Upload Fastq Files</p> <p>Upload Fastq files to ReadStore. Check if file exists and has read permissions.</p> <p>fastq_name: List of Fastq names for files to upload read_type: List of read types for files to upload</p> <p>Parameters:</p> Name Type Description Default <code>fastq_path</code> <code>str</code> <p>List of Fastq files to upload</p> required <code>fastq_name</code> <code>str | None</code> <p>List of Fastq names for files to upload</p> <code>None</code> <code>read_types</code> <p>List of read types for files to upload</p> required <code>read_types</code> <p>Must be in ['R1', 'R2', 'I1', 'I2']</p> required <p>Raises:</p> Type Description <code>ReadStoreError</code> <p>If file not found</p> <code>ReadStoreError</code> <p>If no read permissions</p> <code>ReadStoreError</code> <p>If upload URL request failed</p> Source code in <code>readstore_cli/rsclient.py</code> <pre><code>def upload_fastq(self,\n                 fastq_path: str,\n                 fastq_name: str | None = None,\n                 read_type: str | None = None) -&gt; None:\n    \"\"\"Upload Fastq Files\n\n    Upload Fastq files to ReadStore.\n    Check if file exists and has read permissions.\n\n    fastq_name: List of Fastq names for files to upload\n    read_type: List of read types for files to upload\n\n    Args:\n        fastq_path: List of Fastq files to upload\n        fastq_name: List of Fastq names for files to upload\n        read_types: List of read types for files to upload\n        read_types: Must be in ['R1', 'R2', 'I1', 'I2']\n\n    Raises:\n        rsexceptions.ReadStoreError: If file not found\n        rsexceptions.ReadStoreError: If no read permissions\n        rsexceptions.ReadStoreError: If upload URL request failed\n    \"\"\"\n\n    fq_upload_endpoint = os.path.join(self.endpoint, self.FASTQ_UPLOAD_ENDPOINT)\n\n    # Run parallel uploads of fastq files\n    fastq_path = os.path.abspath(fastq_path)\n\n    # Make sure file exists and\n    if not os.path.exists(fastq_path):\n        raise rsexceptions.ReadStoreError(f\"File Not Found: {fastq_path}\")\n    elif not os.access(fastq_path, os.R_OK):\n        raise rsexceptions.ReadStoreError(f\"No read permissions: {fastq_path}\")\n\n    payload = {\n        \"fq_file_path\": fastq_path,\n    }\n\n    if not fastq_name is None:\n        if fastq_name == \"\":\n            raise rsexceptions.ReadStoreError(\"Fastq Name Is Empty\")\n        if not self.validate_charset(fastq_name):\n            raise rsexceptions.ReadStoreError(\"Invalid Fastq Name\")\n        payload[\"fq_file_name\"] = fastq_name\n\n    if not read_type is None:\n        if read_type not in [\"R1\", \"R2\", \"I1\", \"I2\"]:\n            raise rsexceptions.ReadStoreError(\"Invalid Read Type\")\n        payload[\"read_type\"] = read_type\n\n    res = requests.post(fq_upload_endpoint, json=payload, auth=self.auth)\n\n    if res.status_code not in [200, 204]:\n        res_message = res.json().get(\"detail\", \"No Message\")\n        raise rsexceptions.ReadStoreError(\n            f\"Upload URL Request Failed: {res_message}\"\n        )\n</code></pre>"},{"location":"reference/readstore/#readstore_cli.rsclient.RSClient.upload_pro_data","title":"<code>upload_pro_data(name, pro_data_path, data_type, dataset_id=None, dataset_name=None, metadata={}, description='')</code>","text":"<p>Upload Processed Data</p> <p>Upload Pro Data to ReadStore</p> <p>Parameters:</p> Name Type Description Default <code>pro_data</code> <p>Pro Data in JSON format</p> required <p>Raises:</p> Type Description <code>ReadStoreError</code> <p>If upload request failed</p> Source code in <code>readstore_cli/rsclient.py</code> <pre><code>def upload_pro_data(self,\n                    name: str,\n                    pro_data_path: str,\n                    data_type: str,\n                    dataset_id: int | None = None,\n                    dataset_name: str | None = None,\n                    metadata: dict = {},\n                    description: str = \"\") -&gt; None:\n    \"\"\"Upload Processed Data\n\n    Upload Pro Data to ReadStore\n\n    Args:\n        pro_data: Pro Data in JSON format\n\n    Raises:\n        rsexceptions.ReadStoreError: If upload request failed\n    \"\"\"\n\n    pro_data_endpoint = os.path.join(self.endpoint, self.PRO_DATA_ENDPOINT)\n\n    # Run parallel uploads of fastq files\n    pro_data_path = os.path.abspath(pro_data_path)\n\n    # Make sure file exists and\n    if not os.path.exists(pro_data_path):\n        raise rsexceptions.ReadStoreError(f\"File Not Found: {pro_data_path}\")\n    elif not os.access(pro_data_path, os.R_OK):\n        raise rsexceptions.ReadStoreError(f\"No read permissions: {pro_data_path}\")\n\n    # Define json for post request\n    json = {\n        \"name\" : name,\n        \"data_type\": data_type,\n        \"upload_path\": pro_data_path,\n        \"metadata\": metadata,\n        \"description\" : description,\n    }\n\n    if dataset_id:\n        json['dataset_id'] = dataset_id\n    if dataset_name:\n        json['dataset_name'] = dataset_name        \n\n    res = requests.post(pro_data_endpoint, json=json, auth=self.auth)\n\n    if res.status_code == 403:\n        raise rsexceptions.ReadStoreError(f\"Upload ProData Failed: {res.json().get('detail')}\")\n    elif res.status_code not in [201, 204]:\n        raise rsexceptions.ReadStoreError(\"upload_pro_data failed\")\n</code></pre>"},{"location":"reference/readstore/#readstore_cli.rsclient.RSClient.validate_charset","title":"<code>validate_charset(query_str)</code>","text":"<p>Validate charset for query string</p> <p>Parameters:</p> Name Type Description Default <code>query_str</code> <code>str</code> <p>Query string to validate</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> Source code in <code>readstore_cli/rsclient.py</code> <pre><code>def validate_charset(self, query_str: str) -&gt; bool:\n    \"\"\"\n    Validate charset for query string\n\n    Args:\n        query_str (str): Query string to validate\n\n    Returns:\n        bool: \n    \"\"\"\n\n    allowed = string.digits + string.ascii_lowercase + string.ascii_uppercase + '_-.@'\n    allowed = set(allowed)\n\n    return set(query_str) &lt;= allowed\n</code></pre>"},{"location":"reference/readstore/#rsexceptions-module","title":"rsexceptions module","text":""},{"location":"reference/readstore/#readstore_cli.rsexceptions.ReadStoreError","title":"<code>ReadStoreError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Base class for ReadStoreError exceptions.</p> Source code in <code>readstore_cli/rsexceptions.py</code> <pre><code>class ReadStoreError(Exception):\n    \"\"\"Base class for ReadStoreError exceptions.\"\"\"\n    def __init__(self, message: str):\n        super().__init__(message)\n        self.message = message\n</code></pre>"}]}